# -*- coding: utf-8 -*-
# Streamlit ë° ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st
import os
import uuid
from typing import List

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_core.messages.chat import ChatMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_community.vectorstores import FAISS
from langchain_experimental.tools import PythonREPLTool
from langchain_core.tools.retriever import create_retriever_tool
from langchain_core.prompts import PromptTemplate
from langchain_tavily import TavilySearch
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent
from langchain_teddynote import logging
from langchain_teddynote.messages import stream_graph

# í™˜ê²½ ì„¤ì •
from dotenv import load_dotenv

# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
load_dotenv(override=True)

# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com
logging.langsmith("LangChain-Tutorial")

# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists(".cache"):
    os.mkdir(".cache")
if not os.path.exists(".cache/files"):
    os.mkdir(".cache/files")

# Streamlit ì•± ì œëª© ì„¤ì •
st.title("ReAct Agent ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "agent" not in st.session_state:
    st.session_state["agent"] = None
if "thread_id" not in st.session_state:
    st.session_state["thread_id"] = str(uuid.uuid4())
if "tools" not in st.session_state:
    st.session_state["tools"] = []
if "memory" not in st.session_state:
    # ì „ì—­ ë©”ëª¨ë¦¬ ì¸ìŠ¤í„´ìŠ¤ - í•œ ë²ˆë§Œ ìƒì„±ë˜ê³  ê³„ì† ìœ ì§€ë¨
    st.session_state["memory"] = MemorySaver()
if "current_tool_config" not in st.session_state:
    # ë„êµ¬ ì„¤ì • ë³€ê²½ ê°ì§€ë¥¼ ìœ„í•œ ìƒíƒœ
    st.session_state["current_tool_config"] = None


def create_web_search_tool() -> TavilySearch:
    """ì›¹ ê²€ìƒ‰ ë„êµ¬ ìƒì„±"""
    web_search = TavilySearch(
        topic="general",
        max_results=3,
        include_answer=False,
        include_raw_content=False,
        include_images=False,
        format_output=False,
    )
    web_search.name = "web_search"
    web_search.description = (
        "Use this tool to search on the web for current information, news, and general topics. "
        "Perfect for finding real-time data, latest news, or any information not in your training data."
    )
    return web_search


def create_python_repl_tool() -> PythonREPLTool:
    """Python REPL ì½”ë“œ ì‹¤í–‰ ë„êµ¬ ìƒì„±"""
    python_tool = PythonREPLTool()
    python_tool.name = "python_repl"
    python_tool.description = (
        "A Python shell that can execute Python code and return results. "
        "Use this for calculations, data analysis, generating charts, and any computational tasks. "
        "Remember to use print() to see output results."
    )
    return python_tool


def create_pdf_retriever_tool(uploaded_file) -> object:
    """PDF ë¦¬íŠ¸ë¦¬ë²„ ë„êµ¬ ìƒì„±"""
    if uploaded_file is None:
        return None
    
    # PDF íŒŒì¼ ì €ì¥
    file_content = uploaded_file.read()
    file_path = f"./.cache/files/{uploaded_file.name}"
    with open(file_path, "wb") as f:
        f.write(file_content)
    
    # PDF ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
    loader = PDFPlumberLoader(file_path)
    documents = loader.load()
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=100
    )
    split_docs = text_splitter.split_documents(documents)
    
    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vector_store = FAISS.from_documents(split_docs, embeddings)
    retriever = vector_store.as_retriever(search_kwargs={"k": 6})
    
    # ë¦¬íŠ¸ë¦¬ë²„ ë„êµ¬ ìƒì„±
    retriever_tool = create_retriever_tool(
        retriever,
        "pdf_retriever",
        f"Search and return information from the uploaded PDF file: {uploaded_file.name}. "
        f"This tool contains the full content of the document and can answer questions about it.",
        document_prompt=PromptTemplate.from_template(
            "<document><content>{page_content}</content><metadata><source>{source}</source><page>{page}</page></metadata></document>"
        ),
    )
    return retriever_tool


def create_react_agent_executor(selected_tools: List, model_name: str = "gpt-4.1", temperature: float = 0.1):
    """ReAct Agent ìƒì„±"""
    # LLM ëª¨ë¸ ì„¤ì •
    model = ChatOpenAI(model_name=model_name, temperature=temperature)
    
    # ê¸°ì¡´ ë©”ëª¨ë¦¬ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© (ëŒ€í™” ê¸°ë¡ ìœ ì§€)
    memory = st.session_state["memory"]
    
    # ReAct Agent ìƒì„±
    agent_executor = create_react_agent(
        model, 
        selected_tools, 
        checkpointer=memory
    )
    
    return agent_executor


def print_messages():
    """ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ í™”ë©´ì— í‘œì‹œ"""
    if st.session_state["messages"]:
        for msg_data in st.session_state["messages"]:
            # ë©”ì‹œì§€ê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš° (ë„êµ¬ í˜¸ì¶œ ì •ë³´ í¬í•¨)
            if isinstance(msg_data, dict):
                role = msg_data.get("role")
                content = msg_data.get("content")
                tool_calls = msg_data.get("tool_calls", [])
                
                with st.chat_message(role):
                    # ë„êµ¬ í˜¸ì¶œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ë¨¼ì € í‘œì‹œ
                    if tool_calls:
                        with st.expander(f"ğŸ› ï¸ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=False):
                            for i, tool_call in enumerate(tool_calls, 1):
                                st.markdown(f"**{i}. {tool_call['name']}**")
                                
                                # ë„êµ¬ í˜¸ì¶œ ì¸ì í‘œì‹œ
                                if tool_call['args']:
                                    st.markdown("ğŸ“ **í˜¸ì¶œ ì¸ì:**")
                                    for key, value in tool_call['args'].items():
                                        # ê°’ì´ ë„ˆë¬´ ê¸´ ê²½ìš° ì¶•ì•½
                                        if isinstance(value, str) and len(value) > 100:
                                            value = value[:100] + "..."
                                        st.markdown(f"  â€¢ `{key}`: {value}")
                                
                                # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í‘œì‹œ
                                if 'result' in tool_call:
                                    st.markdown("ğŸ“Š **ì‹¤í–‰ ê²°ê³¼:**")
                                    st.code(tool_call['result'], language="text")
                                
                                if i < len(tool_calls):
                                    st.divider()
                    
                    # AI ì‘ë‹µ í‘œì‹œ
                    st.markdown(content)
            
            # ê¸°ì¡´ ChatMessage í˜•íƒœì¸ ê²½ìš° (í•˜ìœ„ í˜¸í™˜ì„±)
            else:
                st.chat_message(msg_data.role).write(msg_data.content)
    else:
        st.info("ğŸ’­ ì•ˆë…•í•˜ì„¸ìš”! ReAct Agentì™€ ëŒ€í™”í•´ë³´ì„¸ìš”. ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


def add_message(role: str, message: str, tool_calls: list = None):
    """ìƒˆë¡œìš´ ëŒ€í™” ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ë„êµ¬ í˜¸ì¶œ ì •ë³´ í¬í•¨)"""
    msg_data = {
        "role": role,
        "content": message,
        "tool_calls": tool_calls or []
    }
    st.session_state["messages"].append(msg_data)


# ì‚¬ì´ë“œë°” UI êµ¬ì„±
with st.sidebar:
    st.header("âš™ï¸ Agent ì„¤ì •")
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state["messages"] = []
        st.session_state["thread_id"] = str(uuid.uuid4())  # ìƒˆë¡œìš´ thread_id ìƒì„±
        st.rerun()
    
    st.divider()
    
    # ëª¨ë¸ ì„¤ì •
    st.subheader("âœ… ëª¨ë¸ ì„¤ì •")
    selected_model = st.selectbox(
        "LLM ëª¨ë¸ ì„ íƒ",
        ["gpt-4.1", "gpt-4.1-mini"],
        index=0,
        help="ì‚¬ìš©í•  ì–¸ì–´ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."
    )
    
    temperature = st.slider(
        "ğŸŒ¡ï¸ Temperature (ì°½ì˜ì„±)",
        min_value=0.0,
        max_value=1.0,
        value=0.1,
        step=0.1,
        help="0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •í™•í•˜ê³  ì¼ê´€ëœ ë‹µë³€, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€"
    )
    
    # ë‹µë³€ ê¸¸ì´ ì¡°ì ˆ ìŠ¬ë¼ì´ë”
    response_length = st.slider(
        "ğŸ“ ë‹µë³€ ê¸¸ì´ ì„¤ì •",
        min_value=1,
        max_value=5,
        value=3,
        help="1: ê°„ë‹¨ (1-2ë¬¸ì¥), 2: ì§§ìŒ (1ë¬¸ë‹¨), 3: ë³´í†µ (2-3ë¬¸ë‹¨), 4: ìì„¸í•¨ (4-5ë¬¸ë‹¨), 5: ë§¤ìš° ìì„¸í•¨ (5ë¬¸ë‹¨ ì´ìƒ)"
    )
    
    st.divider()
    
    # ë„êµ¬ ì„ íƒ
    st.subheader("ğŸ› ï¸ ë„êµ¬ ì„ íƒ")
    
    # ì›¹ ê²€ìƒ‰ ë„êµ¬
    use_web_search = st.checkbox(
        "ğŸŒ ì›¹ ê²€ìƒ‰ ë„êµ¬",
        value=True,
        help="ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤."
    )
    
    # Python ì½”ë“œ ì‹¤í–‰ ë„êµ¬
    use_python_repl = st.checkbox(
        "ğŸ Python ì½”ë“œ ì‹¤í–‰ ë„êµ¬",
        value=True,
        help="Python ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ê³„ì‚°, ë°ì´í„° ë¶„ì„, ì°¨íŠ¸ ìƒì„± ë“±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
    )
    
    # PDF ì—…ë¡œë“œ ë° ê²€ìƒ‰ ë„êµ¬
    st.subheader("ğŸ“„ PDF ë¬¸ì„œ ë„êµ¬")
    uploaded_pdf = st.file_uploader(
        "PDF íŒŒì¼ ì—…ë¡œë“œ",
        type=["pdf"],
        help="PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¬¸ì„œ ë‚´ìš©ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ë„êµ¬ê°€ ì¶”ê°€ë©ë‹ˆë‹¤."
    )
    
    use_pdf_retriever = uploaded_pdf is not None
    


# ë„êµ¬ ì„¤ì • ë° Agent ìƒì„±
def setup_agent():
    """ì„ íƒëœ ë„êµ¬ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ Agent ì„¤ì •"""
    # í˜„ì¬ ë„êµ¬ ì„¤ì •ì„ ë¬¸ìì—´ë¡œ ìƒì„± (ë³€ê²½ ê°ì§€ìš©)
    pdf_name = uploaded_pdf.name if uploaded_pdf else None
    current_config = {
        'web_search': use_web_search,
        'python_repl': use_python_repl, 
        'pdf_retriever': use_pdf_retriever,
        'pdf_name': pdf_name,
        'model': selected_model,
        'temperature': temperature,
        'response_length': response_length
    }
    config_str = str(sorted(current_config.items()))
    
    # ì„¤ì •ì´ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ Agent ì¬ìƒì„±
    if (st.session_state["current_tool_config"] != config_str or 
        st.session_state["agent"] is None):
        
        tools = []
        
        # ì›¹ ê²€ìƒ‰ ë„êµ¬ ì¶”ê°€
        if use_web_search:
            tools.append(create_web_search_tool())
        
        # Python REPL ë„êµ¬ ì¶”ê°€
        if use_python_repl:
            tools.append(create_python_repl_tool())
        
        # PDF ë¦¬íŠ¸ë¦¬ë²„ ë„êµ¬ ì¶”ê°€
        if use_pdf_retriever:
            pdf_tool = create_pdf_retriever_tool(uploaded_pdf)
            if pdf_tool:
                tools.append(pdf_tool)
        
        # Agent ìƒì„± (ë„êµ¬ê°€ ìˆì„ ë•Œë§Œ)
        if tools:
            agent = create_react_agent_executor(
                selected_tools=tools,
                model_name=selected_model,
                temperature=temperature
            )
            # ì„¤ì • ì—…ë°ì´íŠ¸
            st.session_state["current_tool_config"] = config_str
            return agent, tools
        else:
            st.session_state["current_tool_config"] = config_str
            return None, []
    
    # ì„¤ì •ì´ ë³€ê²½ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ê¸°ì¡´ Agent ì‚¬ìš©
    else:
        return st.session_state["agent"], st.session_state["tools"]


# Agent ì„¤ì •
agent, current_tools = setup_agent()
st.session_state["agent"] = agent
st.session_state["tools"] = current_tools

# ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
print_messages()

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ğŸ’¬ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! Agentê°€ í•„ìš”í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.")

# ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬
if user_input:
    if st.session_state["agent"] is None:
        st.error("âš ï¸ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ ì‚¬ìš©í•  ë„êµ¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        # ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ
        st.chat_message("user").write(user_input)
        add_message("user", user_input)
        
        # Agent ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        with st.chat_message("assistant"):
            
            try:
                # ì„¤ì • ì •ë³´
                config = {"configurable": {"thread_id": st.session_state["thread_id"]}}
                inputs = {"messages": [("human", user_input)]}
                
                # Agent ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
                full_response = ""
                tool_calls = []
                
                with st.spinner("ğŸ¤” Agentê°€ ìƒê°í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    # Agent ì‹¤í–‰í•˜ì—¬ ì‘ë‹µ ìƒì„±
                    response = st.session_state["agent"].invoke(inputs, config)
                    
                    # ëª¨ë“  ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë„êµ¬ í˜¸ì¶œ ë° AI ì‘ë‹µ ì¶”ì¶œ
                    if response and "messages" in response:
                        for msg in response["messages"]:
                            # ë„êµ¬ í˜¸ì¶œ ë©”ì‹œì§€ í™•ì¸
                            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                for tool_call in msg.tool_calls:
                                    tool_info = {
                                        'name': tool_call.get('name', 'Unknown Tool'),
                                        'args': tool_call.get('args', {}),
                                        'id': tool_call.get('id', 'unknown')
                                    }
                                    tool_calls.append(tool_info)
                            
                            # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ë©”ì‹œì§€ í™•ì¸
                            elif hasattr(msg, 'type') and msg.type == 'tool':
                                # ê¸°ì¡´ ë„êµ¬ í˜¸ì¶œ ì •ë³´ì— ê²°ê³¼ ì¶”ê°€
                                tool_id = getattr(msg, 'tool_call_id', None)
                                content = getattr(msg, 'content', '')
                                for tool_call in tool_calls:
                                    if tool_call['id'] == tool_id:
                                        tool_call['result'] = content[:200] + "..." if len(content) > 200 else content
                                        break
                        
                        # AIì˜ ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
                        ai_messages = [msg for msg in response["messages"] if hasattr(msg, 'type') and msg.type == 'ai']
                        if ai_messages:
                            full_response = ai_messages[-1].content
                        else:
                            # AIMessage íƒ€ì…ì´ ì•„ë‹Œ ê²½ìš° content ì†ì„± ì§ì ‘ ì ‘ê·¼
                            for msg in reversed(response["messages"]):
                                if hasattr(msg, 'content') and msg.content.strip():
                                    full_response = msg.content
                                    break
                
                # ë„êµ¬ í˜¸ì¶œ ì •ë³´ í‘œì‹œ (í™•ì¥ ê°€ëŠ¥í•œ ì„¹ì…˜ìœ¼ë¡œ)
                if tool_calls:
                    with st.expander(f"ğŸ› ï¸ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=False):
                        for i, tool_call in enumerate(tool_calls, 1):
                            st.markdown(f"**{i}. {tool_call['name']}**")
                            
                            # ë„êµ¬ í˜¸ì¶œ ì¸ì í‘œì‹œ
                            if tool_call['args']:
                                st.markdown("ğŸ“ **í˜¸ì¶œ ì¸ì:**")
                                for key, value in tool_call['args'].items():
                                    # ê°’ì´ ë„ˆë¬´ ê¸´ ê²½ìš° ì¶•ì•½
                                    if isinstance(value, str) and len(value) > 100:
                                        value = value[:100] + "..."
                                    st.markdown(f"  â€¢ `{key}`: {value}")
                            
                            # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í‘œì‹œ
                            if 'result' in tool_call:
                                st.markdown("ğŸ“Š **ì‹¤í–‰ ê²°ê³¼:**")
                                st.code(tool_call['result'], language="text")
                            
                            if i < len(tool_calls):
                                st.divider()
                
                # AI ìµœì¢… ì‘ë‹µ í‘œì‹œ
                if full_response:
                    st.markdown(full_response)
                    add_message("assistant", full_response, tool_calls)
                else:
                    st.error("ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.info("ğŸ’¡ ëª¨ë¸ ì„¤ì •ì„ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

# ì‚¬ì´ë“œë°” í•˜ë‹¨ì— í˜„ì¬ ì„¤ì • ì •ë³´ í‘œì‹œ
with st.sidebar:
    st.divider()
    st.markdown("### ğŸ“Š í˜„ì¬ ì„¤ì •")
    st.caption(f"**ëª¨ë¸:** {selected_model}")
    st.caption(f"**Temperature:** {temperature}")
    st.caption(f"**ë‹µë³€ ê¸¸ì´:** {response_length}")
    st.caption(f"**Thread ID:** {st.session_state['thread_id'][:8]}...")
    st.caption(f"**í™œì„± ë„êµ¬ ê°œìˆ˜:** {len(current_tools)}")
    
    # ë„êµ¬ë³„ ìƒì„¸ ì •ë³´
    if current_tools:
        with st.expander("ğŸ”§ ë„êµ¬ ìƒì„¸ ì •ë³´"):
            for i, tool in enumerate(current_tools):
                tool_name = getattr(tool, 'name', f'Tool {i+1}')
                tool_desc = getattr(tool, 'description', 'No description available')[:100] + "..."
                st.caption(f"**{tool_name}:** {tool_desc}")