# Streamlit ë° ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st
import os

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_core.messages.chat import ChatMessage
from langchain_openai import ChatOpenAI
from langchain_teddynote import logging
from langchain_teddynote.models import MultiModal
from langchain_teddynote.prompts import load_prompt

# í™˜ê²½ ì„¤ì •
from dotenv import load_dotenv


# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
load_dotenv(override=True)

# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com
logging.langsmith("LangGraph-Tutorial")

# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (ì´ë¯¸ì§€ ì—…ë¡œë“œ ì €ì¥ì„ ìœ„í•¨)
if not os.path.exists(".cache"):
    os.mkdir(".cache")

# ì´ë¯¸ì§€ ì—…ë¡œë“œ ì „ìš© í´ë”
if not os.path.exists(".cache/files"):
    os.mkdir(".cache/files")

# ë²¡í„° ì„ë² ë”© ì €ì¥ í´ë” (í–¥í›„ í™•ì¥ì„±ì„ ìœ„í•´ ìœ ì§€)
if not os.path.exists(".cache/embeddings"):
    os.mkdir(".cache/embeddings")

# Streamlit ì•± ì œëª© ì„¤ì •
st.title("ì´ë¯¸ì§€ ì¸ì‹ ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ AI ì±—ë´‡")

# Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•± ì¬ì‹¤í–‰ ì‹œì—ë„ ëŒ€í™” ê¸°ë¡ ìœ ì§€)
if "messages" not in st.session_state:
    # ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    st.session_state["messages"] = []

# ì„¸ì…˜ ìƒíƒœì— í˜„ì¬ ì´ë¯¸ì§€ ê´€ë¦¬
if "current_image" not in st.session_state:
    st.session_state["current_image"] = None


# ì‚¬ì´ë“œë°” UI êµ¬ì„±
with st.sidebar:
    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
    clear_btn = st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”")

    # ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
    image_url = st.text_input(
        "ì´ë¯¸ì§€ íŒŒì¼ ë§í¬(URL)",
        help="ì´ë¯¸ì§€ íŒŒì¼ì˜ ë§í¬ë¥¼ ì…ë ¥í•˜ë©´ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

    # ë¶„ì„ ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ ì„ íƒ
    domain_context = st.selectbox(
        "ğŸ¯ ë¶„ì„ ë„ë©”ì¸",
        ["ì¼ë°˜ ë¶„ì„", "ê¸ˆìœµ/ì¬ë¬´ì œí‘œ", "ì˜ë£Œ/í—¬ìŠ¤ì¼€ì–´", "ê¸°ìˆ /IT", "êµìœ¡/í•™ìŠµ"],
        index=0,
        help="ì´ë¯¸ì§€ ë¶„ì„ ì‹œ ì ìš©í•  ì „ë¬¸ ë„ë©”ì¸ì„ ì„ íƒí•˜ì„¸ìš”.",
    )

    # ë‹µë³€ ê¸¸ì´ ì¡°ì ˆ ìŠ¬ë¼ì´ë”
    response_length = st.slider(
        "ğŸ“ ë‹µë³€ ê¸¸ì´ ì„¤ì •",
        min_value=1,
        max_value=5,
        value=3,
        help="1: ê°„ë‹¨ (1-2ë¬¸ì¥), 2: ì§§ìŒ (1ë¬¸ë‹¨), 3: ë³´í†µ (2-3ë¬¸ë‹¨), 4: ìì„¸í•¨ (4-5ë¬¸ë‹¨), 5: ë§¤ìš° ìì„¸í•¨ (5ë¬¸ë‹¨ ì´ìƒ)",
    )

    # Temperature ì„¤ì • (ëª¨ë¸ ì°½ì˜ì„± ì¡°ì ˆ)
    temperature = st.slider(
        "ğŸŒ¡ï¸ Temperature (ì°½ì˜ì„±)",
        min_value=0.0,
        max_value=1.0,
        value=0.1,
        step=0.1,
        help="0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •í™•í•˜ê³  ì¼ê´€ëœ ë‹µë³€, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€",
    )


# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
def print_messages():
    """ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ì— í‘œì‹œ"""
    if st.session_state["messages"]:
        st.markdown("### ğŸ’¬ ëŒ€í™” ê¸°ë¡")
        for chat_message in st.session_state["messages"]:
            st.chat_message(chat_message.role).write(chat_message.content)
    else:
        st.info("ğŸ’­ ì•„ì§ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ ì‹œì‘í•´ ë³´ì„¸ìš”!")


# ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
def add_message(role, message):
    """ìƒˆë¡œìš´ ëŒ€í™” ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥"""
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


# ì™¸ë¶€ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•˜ì—¬ ë©€í‹°ëª¨ë‹¬ ë‹µë³€ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_answer(
    img_url,
    user_prompt,
    temperature=0.1,
    response_length=3,
    domain_context="ê¸ˆìœµ/ì¬ë¬´ì œí‘œ",
):
    """ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ê²°í•©í•œ ë©€í‹°ëª¨ë‹¬ AI ë‹µë³€ ìƒì„±"""
    # ì…ë ¥ê°’ ê²€ì¦
    if not img_url or not user_prompt:
        raise ValueError("ì´ë¯¸ì§€ ì£¼ì†Œ(URL) ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    if not isinstance(user_prompt, str) or user_prompt.strip() == "":
        raise ValueError("ìœ íš¨í•œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # ì™¸ë¶€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
    try:
        prompt_template = load_prompt("prompts/multimodal.yaml", encoding="utf-8")
    except Exception as e:
        raise ValueError(f"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì‹¤íŒ¨: {e}")

    # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ì— ê°’ í• ë‹¹ (None ê°’ ë°©ì§€)
    system_prompt = prompt_template.format(
        response_length=response_length if response_length is not None else 3,
        domain_context=domain_context if domain_context is not None else "ì¼ë°˜ ë¶„ì„",
    )

    # OpenAI ChatGPT ëª¨ë¸ ì´ˆê¸°í™” (ì„¤ì •ëœ temperature ì ìš©)
    llm = ChatOpenAI(
        model="openai/gpt-4.1",
        temperature=temperature,
        api_key=os.getenv("OPENROUTER_API_KEY"),
        base_url=os.getenv("OPENROUTER_BASE_URL"),
    )

    # LangChain ë©€í‹°ëª¨ë‹¬ ê°ì²´ ìƒì„± (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ì²˜ë¦¬)
    try:
        multimodal = MultiModal(
            llm, system_prompt=system_prompt, user_prompt=user_prompt.strip()
        )

        # ì´ë¯¸ì§€ íŒŒì¼ì— ëŒ€í•œ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì§ˆì˜ ë° ë‹µë³€ ìƒì„±
        answer = multimodal.stream(image_url)
        return answer
    except Exception as e:
        raise RuntimeError(f"ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ í´ë¦­ ì‹œ
if clear_btn:
    st.session_state["messages"] = []
    # st.session_state["current_image"] = None  # ì´ë¯¸ì§€ëŠ” ìœ ì§€
    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

# ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬
if image_url:
    st.session_state["current_image"] = image_url

# í˜„ì¬ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
if st.session_state["current_image"]:
    st.subheader("ğŸ–¼ï¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
    st.image(st.session_state["current_image"], use_container_width=True)
    st.divider()

# AI ì–´ì‹œìŠ¤í„´íŠ¸ ì˜ì—­
st.subheader("ğŸ’¬ AI ì–´ì‹œìŠ¤í„´íŠ¸")

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# ì‚¬ìš©ìì˜ ì…ë ¥
user_input = st.chat_input("ğŸ“ ì´ë¯¸ì§€ ë‚´ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ê²½ê³  ë©”ì‹œì§€ë¥¼ ë„ìš°ê¸° ìœ„í•œ ë¹ˆ ì˜ì—­
warning_msg = st.empty()

# ë§Œì•½ì— ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´...
if user_input:
    # í˜„ì¬ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
    if st.session_state["current_image"]:
        # í˜„ì¬ ì´ë¯¸ì§€ ì‚¬ìš©
        img = st.session_state["current_image"]

        try:
            # ë‹µë³€ ìš”ì²­ (ìƒˆë¡œìš´ êµ¬ì„± ì˜µì…˜ë“¤ì„ í¬í•¨)
            response = generate_answer(
                img_url=img,
                user_prompt=user_input,
                temperature=temperature,
                response_length=response_length,
                domain_context=domain_context,
            )
        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ğŸ’¡ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê±°ë‚˜, ë‹¤ë¥¸ ì´ë¯¸ì§€ë‚˜ ì§ˆë¬¸ì„ ì‚¬ìš©í•´ ë³´ì„¸ìš”.")
            response = None

        # ì‘ë‹µì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ ê²½ìš°ì—ë§Œ ì±„íŒ… í‘œì‹œ
        if response is not None:
            # ì‚¬ìš©ìì˜ ì…ë ¥ í‘œì‹œ
            st.chat_message("user").write(user_input)

            with st.chat_message("assistant"):
                ai_answer = st.write_stream(response)

            # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
            add_message("user", user_input)
            add_message("assistant", ai_answer)
    else:
        # ì´ë¯¸ì§€ íŒŒì¼ ë¯¸ì—…ë¡œë“œ ì‹œ ê²½ê³  ë©”ì‹œì§€
        st.error("âš ï¸ ë¨¼ì € ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
