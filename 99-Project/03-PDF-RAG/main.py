# Streamlit ë° ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st
import os

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain.storage import LocalFileStore
from langchain.embeddings import CacheBackedEmbeddings
from langchain_core.messages.chat import ChatMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_community.vectorstores import FAISS
from langchain_teddynote.prompts import load_prompt
from langchain_teddynote import logging

# í™˜ê²½ ì„¤ì •
from dotenv import load_dotenv

# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
load_dotenv(override=True)

# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com
logging.langsmith("LangChain-Tutorial")

# Streamlit ì•± ì œëª© ì„¤ì •
st.title("ğŸ“„ PDF ê¸°ë°˜ QA ì‹œìŠ¤í…œ")

# Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•± ì¬ì‹¤í–‰ ì‹œì—ë„ ëŒ€í™” ê¸°ë¡ ìœ ì§€)
if "messages" not in st.session_state:
    # ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    st.session_state["messages"] = []

if "chain" not in st.session_state:
    # RAG ì²´ì¸ ì´ˆê¸°í™”
    st.session_state["chain"] = None

if "embeddings_initialized" not in st.session_state:
    # ì„ë² ë”© ì´ˆê¸°í™” ì—¬ë¶€ ì¶”ì 
    st.session_state["embeddings_initialized"] = False

if "loaded_pdf_files" not in st.session_state:
    # ë¡œë“œëœ PDF íŒŒì¼ ëª©ë¡
    st.session_state["loaded_pdf_files"] = []

# ì‚¬ì´ë“œë°” UI êµ¬ì„±
with st.sidebar:
    # ë¡œë“œëœ PDF íŒŒì¼ ì •ë³´ í‘œì‹œ
    if st.session_state["loaded_pdf_files"]:
        st.info(
            f"ğŸ“ ë¡œë“œëœ PDF íŒŒì¼ ({len(st.session_state['loaded_pdf_files'])}ê°œ):\n\n"
            + "\n".join([f"â€¢ {file}" for file in st.session_state["loaded_pdf_files"]])
        )

    # PDF ì¬ë¡œë“œ ë²„íŠ¼
    reload_btn = st.button("ğŸ”„ PDF ì¬ë¡œë“œ")

    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
    clear_btn = st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”")

    # ë‹µë³€ ê¸¸ì´ ì¡°ì ˆ ìŠ¬ë¼ì´ë”
    response_length = st.slider(
        "ğŸ“ ë‹µë³€ ê¸¸ì´ ì„¤ì •",
        min_value=1,
        max_value=5,
        value=3,
        help="1: ê°„ë‹¨ (1-2ë¬¸ì¥), 2: ì§§ìŒ (1ë¬¸ë‹¨), 3: ë³´í†µ (2-3ë¬¸ë‹¨), 4: ìì„¸í•¨ (4-5ë¬¸ë‹¨), 5: ë§¤ìš° ìì„¸í•¨ (5ë¬¸ë‹¨ ì´ìƒ)",
    )

    # ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜ ì¡°ì ˆ ìŠ¬ë¼ì´ë”
    search_k = st.slider(
        "ğŸ” ê²€ìƒ‰ ë¬¸ì„œ ê°œìˆ˜ ì„¤ì •",
        min_value=4,
        max_value=10,
        value=6,
        help="ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ì²­í¬ë¥¼ ëª‡ ê°œê¹Œì§€ ê²€ìƒ‰í• ì§€ ì„¤ì •í•©ë‹ˆë‹¤. ë§ì„ìˆ˜ë¡ ë” ë§ì€ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì§€ë§Œ ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§‘ë‹ˆë‹¤.",
    )

    # Chunk í¬ê¸° ì¡°ì ˆ ìŠ¬ë¼ì´ë”
    chunk_size = st.slider(
        "ğŸ“ Chunk í¬ê¸° ì„¤ì •",
        min_value=500,
        max_value=2000,
        value=1000,
        step=100,
        help="í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•  ë•Œ ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. í¬ê¸°ê°€ í´ìˆ˜ë¡ ë” ë§ì€ ë¬¸ë§¥ì„ í¬í•¨í•˜ì§€ë§Œ ê²€ìƒ‰ ì •í™•ë„ê°€ ë‚®ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

    # Chunk overlap ì¡°ì ˆ ìŠ¬ë¼ì´ë”
    chunk_overlap = st.slider(
        "ğŸ”— Chunk Overlap ì„¤ì •",
        min_value=0,
        max_value=200,
        value=50,
        step=10,
        help="ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ê²¹ì¹¨ì´ ìˆìœ¼ë©´ ë¬¸ë§¥ ì—°ê²°ì„±ì´ í–¥ìƒë©ë‹ˆë‹¤.",
    )


# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
def print_messages():
    """ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ ìˆœì„œëŒ€ë¡œ í™”ë©´ì— í‘œì‹œ"""
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)


# ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
def add_message(role, message):
    """ìƒˆë¡œìš´ ëŒ€í™” ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥"""
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


def format_docs(docs):
    return "\n".join(
        [
            f"<document><content>{doc.page_content}</content><metadata><page>{doc.metadata['page']+1}</page><source>{doc.metadata['source']}</source></metadata></document>"
            for i, doc in enumerate(docs)
        ]
    )


# data/ í´ë”ì˜ ëª¨ë“  PDF íŒŒì¼ì„ ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def embed_pdfs_from_data_folder(chunk_size=1000, chunk_overlap=50, search_k=6):
    """data/ í´ë”ì˜ ëª¨ë“  PDFë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
    # ë‹¨ê³„ 1: data/ í´ë”ì˜ ëª¨ë“  PDF íŒŒì¼ ì°¾ê¸°
    data_folder = "./data"
    if not os.path.exists(data_folder):
        os.makedirs(data_folder)
        st.warning("âš ï¸ data/ í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ data/ í´ë”ì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return None

    pdf_files = [f for f in os.listdir(data_folder) if f.endswith(".pdf")]

    if not pdf_files:
        st.warning(
            "âš ï¸ data/ í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ data/ í´ë”ì— ì¶”ê°€í•´ì£¼ì„¸ìš”."
        )
        return None

    # ë‹¨ê³„ 2: ëª¨ë“  PDF íŒŒì¼ì„ ë¡œë“œ
    all_docs = []
    for pdf_file in pdf_files:
        file_path = os.path.join(data_folder, pdf_file)
        loader = PDFPlumberLoader(file_path)
        docs = loader.load()
        all_docs.extend(docs)

    # ë‹¨ê³„ 3: ë¬¸ì„œ ë¶„í•  (ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,  # ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜
        chunk_overlap=chunk_overlap,  # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ (ë¬¸ë§¥ ì—°ê²°ì„± ìœ ì§€)
    )
    split_documents = text_splitter.split_documents(all_docs)

    # ë‹¨ê³„ 4: ì„ë² ë”©(Embedding) ìƒì„±
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=os.getenv("OPENROUTER_API_KEY"),
        base_url=os.getenv("EMBEDDING_BASE_URL"),
    )

    # ë‹¨ê³„ 5: FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (ë¹ ë¥¸ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìœ„í•¨)
    vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)

    # ë‹¨ê³„ 6: ê²€ìƒ‰ê¸°(Retriever) ìƒì„± (ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ì²­í¬ë¥¼ ì°¾ëŠ” ì—­í• )
    retriever = vectorstore.as_retriever(
        search_kwargs={"k": search_k}  # ì„¤ì •ëœ ê°œìˆ˜ì˜ ê´€ë ¨ ë¬¸ì„œ ë°˜í™˜
    )
    return retriever, pdf_files


# RAG ì²´ì¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ê²€ìƒ‰-ìƒì„± íŒŒì´í”„ë¼ì¸)
def create_chain(retriever, model_name="gpt-4.1", response_length=3):
    """Retrieval-Augmented Generation ì²´ì¸ ìƒì„±"""
    # ë‹¨ê³„ 6: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
    prompt = load_prompt("prompts/pdf-rag.yaml", encoding="utf-8")

    # ë‹¨ê³„ 7: OpenAI ì–¸ì–´ëª¨ë¸ ì´ˆê¸°í™” (temperature=0ìœ¼ë¡œ ì¼ê´€ëœ ë‹µë³€ ìƒì„±)
    llm = ChatOpenAI(
        model="openai/gpt-4.1",
        temperature=0,
        api_key=os.getenv("OPENROUTER_API_KEY"),
        base_url=os.getenv("OPENROUTER_BASE_URL"),
    )

    # ë‹¨ê³„ 8: RAG ì²´ì¸ êµ¬ì„± (ê²€ìƒ‰ â†’ í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ ì¶œë ¥ íŒŒì‹±)
    chain = (
        {
            "context": retriever | format_docs,  # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            "question": RunnablePassthrough(),  # ì‚¬ìš©ì ì§ˆë¬¸ ì „ë‹¬
            "response_length": lambda _: response_length,  # ë‹µë³€ ê¸¸ì´ ì„¤ì • ì „ë‹¬
        }
        | prompt  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©
        | llm  # ì–¸ì–´ëª¨ë¸ë¡œ ë‹µë³€ ìƒì„±
        | StrOutputParser()  # ë¬¸ìì—´ í˜•íƒœë¡œ ê²°ê³¼ íŒŒì‹±
    )
    return chain


# ì•± ì‹œì‘ ì‹œ data/ í´ë”ì˜ PDF íŒŒì¼ ìë™ ë¡œë“œ
if not st.session_state["embeddings_initialized"]:
    with st.spinner("ğŸ“„ data/ í´ë”ì˜ PDF íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        result = embed_pdfs_from_data_folder(
            chunk_size=chunk_size, chunk_overlap=chunk_overlap, search_k=search_k
        )

        if result is not None:
            retriever, pdf_files = result
            # RAG ì²´ì¸ ìƒì„±
            chain = create_chain(retriever, response_length=response_length)
            st.session_state["chain"] = chain
            st.session_state["embeddings_initialized"] = True
            st.session_state["loaded_pdf_files"] = pdf_files
            st.success(
                f"âœ… {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\n\n"
                f"ğŸ“ ë¡œë“œëœ íŒŒì¼: {', '.join(pdf_files)}"
            )
        else:
            st.session_state["embeddings_initialized"] = True

# PDF ì¬ë¡œë“œ ë²„íŠ¼ í´ë¦­ ì‹œ
if reload_btn:
    st.session_state["embeddings_initialized"] = False
    st.session_state["chain"] = None
    st.session_state["messages"] = []
    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

# ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ í´ë¦­ ì‹œ
if clear_btn:
    st.session_state["messages"] = []
    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ì°½
user_input = st.chat_input("ğŸ“ PDF ë‚´ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ê²½ê³  ë©”ì‹œì§€ í‘œì‹œë¥¼ ìœ„í•œ ë¹ˆ ê³µê°„
warning_msg = st.empty()

# ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ ë° ë‹µë³€ ìƒì„±
if user_input:
    chain = st.session_state["chain"]

    if chain is not None:
        # ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ
        st.chat_message("user").write(user_input)
        # RAG ì²´ì¸ì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„±
        response = chain.stream(user_input)
        # AI ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‹¤ì‹œê°„ í‘œì‹œ
        with st.chat_message("assistant"):
            ai_answer = st.write_stream(response)

        # ëŒ€í™” ê¸°ë¡ì„ ì„¸ì…˜ì— ì €ì¥
        add_message("user", user_input)
        add_message("assistant", ai_answer)
    else:
        # PDF íŒŒì¼ì´ ì—†ì„ ì‹œ ê²½ê³  ë©”ì‹œì§€
        warning_msg.error(
            "âš ï¸ data/ í´ë”ì— PDF íŒŒì¼ì„ ì¶”ê°€í•œ í›„ ì•±ì„ ë‹¤ì‹œ ì‹œì‘í•´ ì£¼ì„¸ìš”."
        )
