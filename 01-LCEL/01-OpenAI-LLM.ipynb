{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "z52x0tivhe",
   "metadata": {},
   "source": [
    "# ğŸ¤– OpenAI ChatGPT APIì™€ LangChain í™œìš© ì™„ì „ ê°€ì´ë“œ\n",
    "\n",
    "## ğŸ“š ê°œìš”\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” **OpenAIì˜ ChatGPT API**ë¥¼ **LangChain í”„ë ˆì„ì›Œí¬**ì™€ í•¨ê»˜ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. \n",
    "\n",
    "### ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "- **LangChain**ê³¼ **LCEL(LangChain Expression Language)** ê¸°ë³¸ ê°œë… ì´í•´\n",
    "- **ChatOpenAI** í´ë˜ìŠ¤ í™œìš©ë²• ì™„ì „ ì •ë³µ\n",
    "- **ë‹¤ì–‘í•œ ëª¨ë¸ ì˜µì…˜**ê³¼ **ì„¤ì • ë°©ë²•** ì´í•´\n",
    "- **ë©€í‹°ëª¨ë‹¬(ì´ë¯¸ì§€ ì¸ì‹)** ê¸°ëŠ¥ í™œìš©\n",
    "- **ìŠ¤íŠ¸ë¦¬ë°** ë° **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§** ì‹¤ìŠµ\n",
    "\n",
    "### ğŸ“– ëª©ì°¨\n",
    "\n",
    "1. **ğŸ› ï¸ í™˜ê²½ ì„¤ì •** - ê¸°ë³¸ ì„¤ì • ë° LangSmith ì—°ë™\n",
    "2. **ğŸš€ LangChainê³¼ LCEL ê¸°ë³¸ ê°œë…** - í•µì‹¬ ê°œë… ì´í•´\n",
    "3. **ğŸ¤– ChatOpenAI ê¸°ë³¸ ì‚¬ìš©ë²•** - ê°ì²´ ìƒì„±ê³¼ ê¸°ë³¸ ì§ˆì˜\n",
    "4. **ğŸ“Š ì‘ë‹µ êµ¬ì¡° ì´í•´** - AI ë©”ì‹œì§€ í˜•íƒœì™€ ë©”íƒ€ë°ì´í„°\n",
    "5. **ğŸ¯ ê³ ê¸‰ ê¸°ëŠ¥** - LogProb, ìŠ¤íŠ¸ë¦¬ë°, ë©€í‹°ëª¨ë‹¬\n",
    "6. **âœ¨ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§** - System/User í”„ë¡¬í”„íŠ¸ í™œìš©\n",
    "\n",
    "### ğŸ’¡ ì‚¬ì „ ì¤€ë¹„ì‚¬í•­\n",
    "\n",
    "- OpenAI API í‚¤ ë°œê¸‰ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •\n",
    "- Python ê°€ìƒí™˜ê²½ êµ¬ì„± ì™„ë£Œ\n",
    "- ê¸°ë³¸ì ì¸ Python ë¬¸ë²• ì´í•´\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf28f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "# .env íŒŒì¼ì— LANGCHAIN_API_KEYë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"LangChain-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4xwrsfd5d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ LangChainê³¼ LCEL ê¸°ë³¸ ê°œë…\n",
    "\n",
    "### ğŸ”— LangChainì´ë€?\n",
    "\n",
    "**LangChain**ì€ Large Language Model(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ **í†µí•© í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤. \n",
    "\n",
    "#### ğŸ—ï¸ LangChainì˜ í•µì‹¬ ê°€ì¹˜\n",
    "\n",
    "- **ğŸ”§ í‘œì¤€í™”**: ë‹¤ì–‘í•œ LLMì„ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©\n",
    "- **âš¡ íš¨ìœ¨ì„±**: ë³µì¡í•œ AI ì›Œí¬í”Œë¡œìš°ë¥¼ ê°„ë‹¨í•œ ì½”ë“œë¡œ êµ¬í˜„\n",
    "- **ğŸ”„ ì¬ì‚¬ìš©ì„±**: í•œ ë²ˆ ë§Œë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ë‹¤ì–‘í•œ ê³³ì— í™œìš©\n",
    "- **ğŸ› ï¸ í™•ì¥ì„±**: í•„ìš”ì— ë”°ë¼ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€/ë³€ê²½\n",
    "\n",
    "### âš—ï¸ LCEL(LangChain Expression Language)\n",
    "\n",
    "**LCEL**ì€ LangChain ì»´í¬ë„ŒíŠ¸ë“¤ì„ **ì²´ì¸ì²˜ëŸ¼ ì—°ê²°**í•˜ëŠ” ê°•ë ¥í•œ ë¬¸ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ¯ LCELì˜ íŠ¹ì§•\n",
    "\n",
    "```python\n",
    "# ì „í†µì ì¸ ë°©ì‹\n",
    "def traditional_approach(input_text):\n",
    "    prompt_result = prompt.format(input=input_text)\n",
    "    llm_result = llm.invoke(prompt_result)\n",
    "    output_result = output_parser.parse(llm_result)\n",
    "    return output_result\n",
    "\n",
    "# LCEL ë°©ì‹ - ê°„ê²°í•˜ê³  ëª…í™•!\n",
    "chain = prompt | llm | output_parser\n",
    "result = chain.invoke({\"input\": input_text})\n",
    "```\n",
    "\n",
    "#### âœ¨ LCELì˜ ì¥ì \n",
    "\n",
    "- **ğŸ“– ê°€ë…ì„±**: ì²˜ë¦¬ íë¦„ì„ í•œëˆˆì— íŒŒì•… ê°€ëŠ¥\n",
    "- **âš¡ ë³‘ë ¬ ì²˜ë¦¬**: ìë™ìœ¼ë¡œ ìµœì í™”ëœ ì‹¤í–‰\n",
    "- **ğŸ”„ ìŠ¤íŠ¸ë¦¬ë°**: ì‹¤ì‹œê°„ ê²°ê³¼ ì¶œë ¥ ì§€ì›\n",
    "- **ğŸ›¡ï¸ ì˜¤ë¥˜ ì²˜ë¦¬**: ê°•ë ¥í•œ ì˜ˆì™¸ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜\n",
    "\n",
    "### ğŸ’» ì‹¤ì œ í™œìš© ì˜ˆì‹œ\n",
    "\n",
    "```python\n",
    "# í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ ê²°ê³¼ íŒŒì‹±ì˜ ì—°ì‡„ ì‘ì—…\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ê° ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_template(\"Explain {topic} in simple terms\")\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# LCELë¡œ ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# í•œ ë²ˆì˜ í˜¸ì¶œë¡œ ì „ì²´ ê³¼ì • ì‹¤í–‰\n",
    "result = chain.invoke({\"topic\": \"artificial intelligence\"})\n",
    "```\n",
    "\n",
    "ì´ì œ ì‹¤ì œ **ChatOpenAI** í´ë˜ìŠ¤ë¥¼ í™œìš©í•´ë³´ê² ìŠµë‹ˆë‹¤! ğŸ¯\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550920c-09d8-48b3-be2f-b36362c37989",
   "metadata": {},
   "source": [
    "## ğŸ¤– ChatOpenAI - OpenAI ëª¨ë¸ì˜ LangChain ì¸í„°í˜ì´ìŠ¤\n",
    "\n",
    "**ChatOpenAI**ëŠ” OpenAIì˜ ê°•ë ¥í•œ ì–¸ì–´ ëª¨ë¸ë“¤ì„ LangChainì—ì„œ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ëŠ” **í†µí•© ì¸í„°í˜ì´ìŠ¤**ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ¯ ì£¼ìš” ì„¤ì • ì˜µì…˜ë“¤\n",
    "\n",
    "#### ğŸŒ¡ï¸ **temperature** (ì°½ì˜ì„± ì¡°ì ˆ)\n",
    "```python\n",
    "temperature=0.1  # ì¼ê´€ë˜ê³  ì •í™•í•œ ë‹µë³€ (ì‚¬ì‹¤ ì§ˆë¬¸ì— ì í•©)\n",
    "temperature=0.8  # ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ë‹µë³€ (ì°½ì‘ í™œë™ì— ì í•©)\n",
    "```\n",
    "- **ë²”ìœ„**: 0.0 ~ 2.0\n",
    "- **ë‚®ì€ ê°’ (0.0~0.3)**: ì •í™•í•˜ê³  ì¼ê´€ëœ ë‹µë³€, íŒ©íŠ¸ ì²´í¬ì— ìµœì \n",
    "- **ì¤‘ê°„ ê°’ (0.4~0.7)**: ê· í˜•ì¡íŒ ë‹µë³€, ì¼ë°˜ì ì¸ ëŒ€í™”ì— ì í•©  \n",
    "- **ë†’ì€ ê°’ (0.8~2.0)**: ì°½ì˜ì ì´ê³  ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ë‹µë³€, ë¸Œë ˆì¸ìŠ¤í† ë°ì— ìœ ìš©\n",
    "\n",
    "#### ğŸ“ **max_tokens** (ìµœëŒ€ ì¶œë ¥ ê¸¸ì´)\n",
    "```python\n",
    "max_tokens=2048  # ìµœëŒ€ 2048ê°œ í† í°ê¹Œì§€ ìƒì„±\n",
    "```\n",
    "- **í† í°ì´ë€?** ë‹¨ì–´ì˜ ì¼ë¶€ë¶„ ë˜ëŠ” ì „ì²´ (í•œêµ­ì–´ 1í† í° â‰ˆ 2-3ê¸€ì)\n",
    "- **ë¹„ìš© ì ˆì•½ íŒ**: í•„ìš”í•œ ë§Œí¼ë§Œ ì„¤ì •í•˜ì—¬ API ë¹„ìš© ìµœì í™”\n",
    "\n",
    "#### ğŸ·ï¸ **model_name** (ì‚¬ìš©í•  ëª¨ë¸)\n",
    "- **GPT-4.1**: ìµœì‹  ê³ ì„±ëŠ¥ ëª¨ë¸, ë³µì¡í•œ ì¶”ë¡ ê³¼ ë©€í‹°ëª¨ë‹¬ ì§€ì›\n",
    "- **GPT-4.1-mini**: ì„±ëŠ¥ê³¼ ë¹„ìš©ì˜ ê· í˜•, ì¼ë°˜ì ì¸ ì‘ì—…ì— ìµœì \n",
    "- **GPT-4.1-nano**: ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸, ê°„ë‹¨í•œ ì‘ì—…ì— ì í•©\n",
    "\n",
    "### ğŸ“Š OpenAI ëª¨ë¸ ë¹„êµí‘œ\n",
    "\n",
    "| ëª¨ë¸ ê³„ì—´       | ëª¨ë¸ëª… (API Name) | ì…ë ¥       | ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°  | ìµœëŒ€ ì¶œë ¥ í† í° | ì§€ì‹ ë§ˆê°ì¼ (Cutoff) | ê°€ê²© (1Mí† í°ë‹¹)                  |\n",
    "| :---------- | :------------- | :------- | :-------- | :------- | :-------------- | :------------------------------ |\n",
    "| **GPT-5** â­   | `gpt-5`        | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ | 400,000   | 128,000  | 2024ë…„ 9ì›” 30ì¼    | **ì…ë ¥:** $1.25<br>**ì¶œë ¥:** $10.00 |\n",
    "|             | `gpt-5-mini`   | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ | 400,000   | 128,000  | 2024ë…„ 5ì›” 31ì¼    | **ì…ë ¥:** $0.25<br>**ì¶œë ¥:** $2.00  |\n",
    "|             | `gpt-5-nano`   | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ | 400,000   | 128,000  | 2024ë…„ 5ì›” 31ì¼    | **ì…ë ¥:** $0.05<br>**ì¶œë ¥:** $0.40  |\n",
    "| **GPT-4.1** ğŸš€ | `gpt-4.1`      | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ | 1,047,576 | 32,768   | 2024ë…„ 6ì›” 1ì¼     | **ì…ë ¥:** $2.00<br>**ì¶œë ¥:** $8.00  |\n",
    "|             | `gpt-4.1-mini` | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ | 1,047,576 | 32,768   | 2024ë…„ 6ì›” 1ì¼     | **ì…ë ¥:** $0.40<br>**ì¶œë ¥:** $1.60  |\n",
    "|             | `gpt-4.1-nano` | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ | 1,047,576 | 32,768   | 2024ë…„ 6ì›” 1ì¼     | **ì…ë ¥:** $0.10<br>**ì¶œë ¥:** $0.40  |\n",
    "| **GPT-4o**  ğŸ“·  | `gpt-4o`       | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ | 128,000   | 16,384   | 2023ë…„ 10ì›” 1ì¼    | **ì…ë ¥:** $2.50<br>**ì¶œë ¥:** $10.00 |\n",
    "|             | `gpt-4o-mini`  | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ | 128,000   | 16,384   | 2023ë…„ 10ì›” 1ì¼    | **ì…ë ¥:** $0.15<br>**ì¶œë ¥:** $0.60  |\n",
    "\n",
    "![OpenAI Models Comparison](./images/gpt-models3-202508.png)\n",
    "\n",
    "### ğŸ’¡ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ\n",
    "\n",
    "- **ğŸ¯ ì •í™•ì„± ìš°ì„ **: `gpt-4.1` - ë³µì¡í•œ ë¶„ì„, ì „ë¬¸ì  ì‘ì—…\n",
    "- **âš¡ ê· í˜•ì¡íŒ ì„ íƒ**: `gpt-4.1-mini` - ì¼ë°˜ì ì¸ ìš©ë„, ê°€ì„±ë¹„ ìµœê³ \n",
    "- **ğŸ’° ë¹„ìš© ì ˆì•½**: `gpt-4.1-nano` - ê°„ë‹¨í•œ ì§ˆë‹µ, ëŒ€ëŸ‰ ì²˜ë¦¬\n",
    "\n",
    "> **ì°¸ê³  ë§í¬**: [OpenAI ê³µì‹ ëª¨ë¸ ë¬¸ì„œ](https://platform.openai.com/docs/models)\n",
    "\n",
    "### ğŸš€ ê¸°ë³¸ ì‚¬ìš©ë²•\n",
    "\n",
    "ì´ì œ ì‹¤ì œë¡œ ChatOpenAIë¥¼ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc161c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI ê°ì²´ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # ì°½ì˜ì„± (0.0 ~ 2.0) - ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ë‹µë³€\n",
    "    model_name=\"gpt-4.1\",  # ì‚¬ìš©í•  OpenAI ëª¨ë¸ëª…\n",
    ")\n",
    "\n",
    "# ì‚¬ìš©ì ì§ˆì˜ë‚´ìš© ì •ì˜\n",
    "question = \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "\n",
    "# LLMì— ì§ˆì˜í•˜ê³  ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"[ë‹µë³€]: {llm.invoke(question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef2647",
   "metadata": {},
   "source": [
    "### ğŸ“Š ì‘ë‹µ êµ¬ì¡° ì´í•´í•˜ê¸° - AIMessage ê°ì²´\n",
    "\n",
    "ChatOpenAIì˜ ì‘ë‹µì€ ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ **AIMessage ê°ì²´**ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤. ì´ ê°ì²´ì—ëŠ” ë‹¤ì–‘í•œ ìœ ìš©í•œ ì •ë³´ê°€ ë‹´ê²¨ìˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "#### ğŸ” AIMessageì˜ êµ¬ì„± ìš”ì†Œ\n",
    "\n",
    "- **ğŸ’¬ content**: ì‹¤ì œ AIê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸ ë‹µë³€\n",
    "- **ğŸ“Š response_metadata**: í† í° ì‚¬ìš©ëŸ‰, ëª¨ë¸ ì •ë³´, ì²˜ë¦¬ ì‹œê°„ ë“±ì˜ ë©”íƒ€ë°ì´í„°\n",
    "- **ğŸ·ï¸ ê¸°íƒ€ ì •ë³´**: ë©”ì‹œì§€ ID, íƒ€ì… ë“±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af58a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì§ˆì˜ë‚´ìš© ì •ì˜\n",
    "question = \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "\n",
    "# LLMì— ì§ˆì˜í•˜ê³  ì‘ë‹µ ê°ì²´ë¥¼ ë³€ìˆ˜ì— ì €ì¥\n",
    "response = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ì‘ë‹µ ê°ì²´ í™•ì¸ (AIMessage í˜•íƒœ)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd49c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µ ë‚´ìš©ë§Œ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df69214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µ ë©”íƒ€ë°ì´í„° í™•ì¸ (í† í° ì‚¬ìš©ëŸ‰, ëª¨ë¸ ì •ë³´ ë“±)\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4a51a",
   "metadata": {},
   "source": [
    "### ğŸ¯ LogProb - AIì˜ í™•ì‹ ë„ ì¸¡ì •í•˜ê¸°\n",
    "\n",
    "**LogProb(ë¡œê·¸ í™•ë¥ )** ì€ AIê°€ ê° ë‹¨ì–´ë¥¼ ì„ íƒí•  ë•Œì˜ **í™•ì‹ ë„**ë¥¼ ìˆ˜ì¹˜ë¡œ ë³´ì—¬ì£¼ëŠ” ê³ ê¸‰ ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ¤” LogProbì´ ìœ ìš©í•œ ìƒí™©ë“¤\n",
    "\n",
    "- **ğŸ“Š ë‹µë³€ ì‹ ë¢°ë„ í‰ê°€**: AIê°€ ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ì§€ íŒë‹¨\n",
    "- **ğŸ” í’ˆì§ˆ ê´€ë¦¬**: ë¶ˆí™•ì‹¤í•œ ë‹µë³€ì„ í•„í„°ë§\n",
    "- **ğŸ“ˆ ëª¨ë¸ ë¶„ì„**: AIì˜ ì˜ì‚¬ê²°ì • ê³¼ì • ì´í•´\n",
    "- **âš–ï¸ ì—¬ëŸ¬ ë‹µë³€ ë¹„êµ**: ê°€ì¥ í™•ì‹¤í•œ ë‹µë³€ ì„ íƒ\n",
    "\n",
    "#### ğŸ’¡ LogProb í•´ì„ ë°©ë²•\n",
    "\n",
    "- **ë†’ì€ í™•ë¥  (-0.1 ~ 0.0)**: AIê°€ ë§¤ìš° í™•ì‹ í•˜ëŠ” ë‹µë³€\n",
    "- **ì¤‘ê°„ í™•ë¥  (-2.0 ~ -0.1)**: ì¼ë°˜ì ì¸ ìˆ˜ì¤€ì˜ í™•ì‹ \n",
    "- **ë‚®ì€ í™•ë¥  (-5.0 ì´í•˜)**: AIê°€ ë¶ˆí™•ì‹¤í•´í•˜ëŠ” ë‹µë³€\n",
    "\n",
    "> **ğŸ’­ ì‹¤ìƒí™œ ë¹„ìœ **: ì‹œí—˜ì—ì„œ ë‹µì„ ê³ ë¥¼ ë•Œ \"90% í™•ì‹ \" vs \"50% í™•ì‹ \"ê³¼ ê°™ì€ ê°œë…ì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe733438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogProb ê¸°ëŠ¥ì´ í™œì„±í™”ëœ ChatOpenAI ê°ì²´ ìƒì„±\n",
    "llm_with_logprob = ChatOpenAI(\n",
    "    temperature=0.1,  # ì°½ì˜ì„± (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜\n",
    "    model_name=\"gpt-4.1\",  # ì‚¬ìš©í•  OpenAI ëª¨ë¸ëª…\n",
    ").bind(logprobs=True)  # í† í°ë³„ í™•ë¥  ì •ë³´ í™œì„±í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì§ˆì˜ë‚´ìš© ì •ì˜\n",
    "question = \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "\n",
    "# LogProbê°€ í™œì„±í™”ëœ LLMìœ¼ë¡œ ì§ˆì˜\n",
    "response = llm_with_logprob.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogProb ì •ë³´ê°€ í¬í•¨ëœ ë©”íƒ€ë°ì´í„° í™•ì¸\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aec3e6",
   "metadata": {},
   "source": [
    "### âš¡ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ - ì‹¤ì‹œê°„ ì‘ë‹µ ì²´í—˜\n",
    "\n",
    "**ìŠ¤íŠ¸ë¦¬ë°**ì€ AIê°€ ë‹µë³€ì„ **ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±í•˜ë©´ì„œ ì¦‰ì‹œ ë³´ì—¬ì£¼ëŠ”** ê¸°ëŠ¥ì…ë‹ˆë‹¤. ë§ˆì¹˜ ì‚¬ëŒì´ ë§í•˜ë“¯ì´ ë‹¨ì–´ í•˜ë‚˜ì”© ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "#### ğŸ¯ ìŠ¤íŠ¸ë¦¬ë°ì´ ìœ ìš©í•œ ì´ìœ \n",
    "\n",
    "- **â° ì¦‰ì‹œì„±**: ê¸´ ë‹µë³€ë„ ê¸°ë‹¤ë¦¼ ì—†ì´ ë°”ë¡œ í™•ì¸\n",
    "- **ğŸ” íˆ¬ëª…ì„±**: AIê°€ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ì§€ ê³¼ì •ì„ ê´€ì°°\n",
    "- **ğŸ’¬ ìì—°ìŠ¤ëŸ¬ì›€**: ì‹¤ì œ ëŒ€í™”í•˜ëŠ” ë“¯í•œ ê²½í—˜\n",
    "- **âš¡ íš¨ìœ¨ì„±**: ì „ì²´ ë‹µë³€ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦´ í•„ìš” ì—†ìŒ\n",
    "\n",
    "#### ğŸ’¡ í™œìš© ì‹œë‚˜ë¦¬ì˜¤\n",
    "\n",
    "- **ğŸ“ ê¸´ ê¸€ ì‘ì„±**: ì—ì„¸ì´, ë³´ê³ ì„œ ë“±\n",
    "- **ğŸ’¬ ì‹¤ì‹œê°„ ì±—ë´‡**: ëŒ€í™”í˜• ì• í”Œë¦¬ì¼€ì´ì…˜\n",
    "- **ğŸ¥ ë¼ì´ë¸Œ ë°ëª¨**: ì‹œì—°ì´ë‚˜ ë°œí‘œ ì‹œ\n",
    "- **â±ï¸ ê¸´ê¸‰ ì§ˆë¬¸**: ë¹ ë¥¸ í”¼ë“œë°±ì´ í•„ìš”í•  ë•Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ LLMì— ì§ˆì˜\n",
    "# ì‹¤ì‹œê°„ìœ¼ë¡œ í† í°ì´ ìƒì„±ë˜ëŠ” ê³¼ì •ì„ í™•ì¸í•  ìˆ˜ ìˆìŒ\n",
    "answer = llm.stream(\"ëŒ€í•œë¯¼êµ­ì˜ ì•„ë¦„ë‹¤ìš´ ê´€ê´‘ì§€ 10ê³³ê³¼ ì£¼ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a90e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥\n",
    "# ê° í† í°ì´ ìƒì„±ë  ë•Œë§ˆë‹¤ ì¦‰ì‹œ í™”ë©´ì— í‘œì‹œë¨\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f079b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ LLMì— ì§ˆì˜\n",
    "answer = llm.stream(\"ëŒ€í•œë¯¼êµ­ì˜ ì•„ë¦„ë‹¤ìš´ ê´€ê´‘ì§€ 10ê³³ê³¼ ì£¼ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!\")\n",
    "\n",
    "# langchain_teddynoteì˜ stream_response í•¨ìˆ˜ë¡œ ê¹”ë”í•˜ê²Œ ì¶œë ¥\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95ce8b",
   "metadata": {},
   "source": [
    "## ğŸ“· ë©€í‹°ëª¨ë‹¬ AI - ì´ë¯¸ì§€ë¥¼ ì½ëŠ” ì¸ê³µì§€ëŠ¥\n",
    "\n",
    "**ë©€í‹°ëª¨ë‹¬(Multimodal)** ì€ ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë°ì´í„°ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” AI ê¸°ìˆ ì…ë‹ˆë‹¤. **í…ìŠ¤íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤**ê¹Œì§€ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "### ğŸŒˆ ë©€í‹°ëª¨ë‹¬ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°ì´í„° íƒ€ì…\n",
    "\n",
    "- **ğŸ“ í…ìŠ¤íŠ¸**: ë¬¸ì„œ, ì´ë©”ì¼, ì›¹í˜ì´ì§€ ë“±ì˜ ê¸€ì ì •ë³´\n",
    "- **ğŸ–¼ï¸ ì´ë¯¸ì§€**: ì‚¬ì§„, ê·¸ë˜í”„, ë„í‘œ, ìŠ¤í¬ë¦°ìƒ· ë“±ì˜ ì‹œê°ì  ì •ë³´  \n",
    "- **ğŸµ ì˜¤ë””ì˜¤**: ìŒì„±, ìŒì•…, íš¨ê³¼ìŒ ë“±ì˜ ì²­ê°ì  ì •ë³´\n",
    "- **ğŸ¬ ë¹„ë””ì˜¤**: ë™ì˜ìƒ, ì• ë‹ˆë©”ì´ì…˜ ë“± ì‹œì²­ê° ë³µí•© ì •ë³´\n",
    "\n",
    "### ğŸ¯ GPT-4.1ì˜ ë¹„ì „(Vision) ê¸°ëŠ¥\n",
    "\n",
    "**GPT-4.1**ì€ ê°•ë ¥í•œ **ì´ë¯¸ì§€ ì¸ì‹ ëŠ¥ë ¥**ì„ ê°–ì¶˜ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ê°€ëŠ¥í•œ ì‘ì—…ë“¤\n",
    "\n",
    "- **ğŸ“Š ì°¨íŠ¸/ê·¸ë˜í”„ í•´ì„**: ë°ì´í„° ì‹œê°í™” ë¶„ì„\n",
    "- **ğŸ“„ ë¬¸ì„œ OCR**: ì´ë¯¸ì§€ ì† í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° í•´ì„\n",
    "- **ğŸï¸ ì¥ë©´ ì„¤ëª…**: ì‚¬ì§„ ì† ìƒí™©ê³¼ ê°ì²´ ì¸ì‹\n",
    "- **ğŸ“‹ í‘œ/ì–‘ì‹ ì²˜ë¦¬**: ë³µì¡í•œ í…Œì´ë¸” ë°ì´í„° ì´í•´\n",
    "- **ğŸ¨ ì°½ì‘ë¬¼ ë¶„ì„**: ê·¸ë¦¼, ë””ìì¸ ìš”ì†Œ í•´ì„\n",
    "\n",
    "#### ğŸ’¼ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš© ì‚¬ë¡€\n",
    "\n",
    "- **ğŸ“ˆ ì¬ë¬´ì œí‘œ ë¶„ì„**: ë³µì¡í•œ íšŒê³„ ìë£Œ ìë™ í•´ì„\n",
    "- **ğŸ¥ ì˜ë£Œ ì˜ìƒ ê²€í† **: X-ray, MRI ì´ë¯¸ì§€ ë³´ì¡° ë¶„ì„\n",
    "- **ğŸ—ï¸ ê±´ì¶• ë„ë©´ ê²€í† **: ì„¤ê³„ë„ ë° ì‹œê³µ í˜„í™© íŒŒì•…\n",
    "- **ğŸ“¦ ì œí’ˆ ê´€ë¦¬**: ìƒí’ˆ ì‚¬ì§„ì„ í†µí•œ í’ˆì§ˆ ê²€ì‚¬\n",
    "\n",
    "> **ğŸš€ í˜ì‹  í¬ì¸íŠ¸**: ì´ì œ \"ì´ ì´ë¯¸ì§€ì—ì„œ ë­ê°€ ë³´ì´ë‚˜ìš”?\"ê°€ ì•„ë‹ˆë¼ \"ì´ ì¬ë¬´ì œí‘œì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"ê¹Œì§€ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.models import MultiModal\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# ê¸°ë³¸ ChatOpenAI ê°ì²´ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # ì°½ì˜ì„± (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4.1\",  # ì´ë¯¸ì§€ ì¸ì‹ì´ ê°€ëŠ¥í•œ ëª¨ë¸\n",
    ")\n",
    "\n",
    "# ë©€í‹°ëª¨ë‹¬(ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ì²˜ë¦¬) ê°ì²´ ìƒì„±\n",
    "multimodal_llm = MultiModal(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ìƒì˜ ì´ë¯¸ì§€ URL ì •ì˜\n",
    "IMAGE_URL = \"https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg\"\n",
    "\n",
    "# ì›¹ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë¶„ì„í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±\n",
    "answer = multimodal_llm.stream(IMAGE_URL)\n",
    "\n",
    "# ì‹¤ì‹œê°„ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì¶œë ¥\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ec2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œì»¬ ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì •ì˜\n",
    "IMAGE_PATH_FROM_FILE = \"./images/sample-image.png\"\n",
    "\n",
    "# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±\n",
    "answer = multimodal_llm.stream(IMAGE_PATH_FROM_FILE)\n",
    "\n",
    "# ì‹¤ì‹œê°„ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì¶œë ¥\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5fc02",
   "metadata": {},
   "source": [
    "## âœ¨ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ - AIì˜ ì—­í• ê³¼ í–‰ë™ ì„¤ê³„\n",
    "\n",
    "**í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**ì€ AIê°€ ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ **ì •í™•í•œ ì§€ì‹œì‚¬í•­ì„ ì„¤ê³„**í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë§ˆì¹˜ ì „ë¬¸ê°€ë¥¼ ê³ ìš©í•  ë•Œ **ì—…ë¬´ ì„¤ëª…ì„œ**ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤!\n",
    "\n",
    "### ğŸ­ System Prompt vs User Prompt\n",
    "\n",
    "#### ğŸ‘¨â€ğŸ’¼ **System Prompt** - AIì˜ ì •ì²´ì„±ê³¼ ì—­í•  ì •ì˜\n",
    "```python\n",
    "system_prompt = \"You are a professional financial analyst...\"\n",
    "```\n",
    "- **ëª©ì **: AIê°€ **ëˆ„êµ¬ì¸ì§€, ì–´ë–¤ ì „ë¬¸ì„±ì„ ê°€ì ¸ì•¼ í•˜ëŠ”ì§€** ì •ì˜\n",
    "- **íŠ¹ì§•**: ì „ì²´ ëŒ€í™” ì„¸ì…˜ ë™ì•ˆ ì§€ì†ë˜ëŠ” **ê¸°ë³¸ ì„¤ì •**\n",
    "- **ì˜ˆì‹œ**: \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì„œë¹„ìŠ¤ ì§ì›ì…ë‹ˆë‹¤\", \"ë‹¹ì‹ ì€ ì „ë¬¸ ì˜ë£Œì§„ì…ë‹ˆë‹¤\"\n",
    "\n",
    "#### ğŸ—£ï¸ **User Prompt** - êµ¬ì²´ì ì¸ ì‘ì—… ì§€ì‹œì‚¬í•­\n",
    "```python\n",
    "user_prompt = \"Please analyze the financial data and provide insights...\"\n",
    "```\n",
    "- **ëª©ì **: **êµ¬ì²´ì ìœ¼ë¡œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ì§€** ìƒì„¸í•œ ì‘ì—… ëª…ë ¹\n",
    "- **íŠ¹ì§•**: ê° ìš”ì²­ë§ˆë‹¤ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ” **ê°€ë³€ì  ì§€ì‹œì‚¬í•­**\n",
    "- **ì˜ˆì‹œ**: \"ì´ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”\", \"3ê°€ì§€ ëŒ€ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”\"\n",
    "\n",
    "### ğŸ¯ íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„± ì›ì¹™\n",
    "\n",
    "#### 1ï¸âƒ£ **ëª…í™•ì„± (Clarity)**\n",
    "```python\n",
    "# âŒ ì• ë§¤í•œ ì§€ì‹œ\n",
    "\"ì¬ë¬´ì œí‘œë¥¼ ë´ì£¼ì„¸ìš”\"\n",
    "\n",
    "# âœ… ëª…í™•í•œ ì§€ì‹œ  \n",
    "\"ì¬ë¬´ì œí‘œì˜ ìˆ˜ìµì„± ì§€í‘œë¥¼ ë¶„ì„í•˜ê³  3ê°€ì§€ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”\"\n",
    "```\n",
    "\n",
    "#### 2ï¸âƒ£ **êµ¬ì²´ì„± (Specificity)**\n",
    "```python\n",
    "# âŒ ì¶”ìƒì  ìš”ì²­\n",
    "\"ë„ì›€ì„ ì£¼ì„¸ìš”\"\n",
    "\n",
    "# âœ… êµ¬ì²´ì  ìš”ì²­\n",
    "\"ë§¤ì¶œ ì¦ê° ì›ì¸ì„ ë¶„ì„í•˜ê³ , í–¥í›„ 3ê°œì›” ì˜ˆì¸¡ê³¼ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”\"\n",
    "```\n",
    "\n",
    "#### 3ï¸âƒ£ **ë§¥ë½ ì œê³µ (Context)**\n",
    "```python\n",
    "# âœ… í’ë¶€í•œ ë§¥ë½\n",
    "\"ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ì¬ë¬´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¤‘ì†Œê¸°ì—… CEOë¥¼ ëŒ€ìƒìœ¼ë¡œ ë³µì¡í•œ ì¬ë¬´ ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "```\n",
    "\n",
    "### ğŸ’¡ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ ì‹¤ì œ íš¨ê³¼\n",
    "\n",
    "ì¢‹ì€ í”„ë¡¬í”„íŠ¸ëŠ” **AIì˜ ì„±ëŠ¥ì„ 10ë°° ì´ìƒ í–¥ìƒ**ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- **ğŸ¯ ì •í™•ë„ í–¥ìƒ**: ì›í•˜ëŠ” ë‹µë³€ì„ ë” ì •í™•í•˜ê²Œ ìƒì„±\n",
    "- **ğŸ“Š ì¼ê´€ì„± ë³´ì¥**: ë§¤ë²ˆ ë¹„ìŠ·í•œ í’ˆì§ˆì˜ ê²°ê³¼ ì œê³µ  \n",
    "- **âš¡ íš¨ìœ¨ì„± ì¦ëŒ€**: ë°˜ë³µ ì§ˆë¬¸ê³¼ ìˆ˜ì • ì‘ì—… ìµœì†Œí™”\n",
    "- **ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: íŠ¹ì • ì—…ë¬´ë‚˜ ìŠ¤íƒ€ì¼ì— ë§ì¶¤ ì¡°ì •\n",
    "\n",
    "ì´ì œ ì‹¤ì œ ì¬ë¬´ì œí‘œ ë¶„ì„ì— íŠ¹í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤! ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be092af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: AIì˜ ì—­í• ê³¼ í–‰ë™ ë°©ì‹ì„ ì •ì˜\n",
    "system_prompt = \"\"\"You are a professional financial AI assistant specialized in analyzing financial statements and tables. \n",
    "Your mission is to interpret given tabular financial data and provide insightful, interesting findings in a friendly and helpful manner. \n",
    "Focus on key metrics, trends, and notable patterns that would be valuable for business analysis.\"\"\"\n",
    "\n",
    "# ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸: êµ¬ì²´ì ì¸ ì‘ì—… ì§€ì‹œì‚¬í•­\n",
    "user_prompt = \"\"\"Please analyze the financial statement provided in the image. \n",
    "Identify and summarize the most interesting and important findings, including key financial metrics, trends, and insights that would be valuable for business decision-making.\"\"\"\n",
    "\n",
    "# ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ëœ ë©€í‹°ëª¨ë‹¬ ê°ì²´ ìƒì„±\n",
    "multimodal_llm_with_prompt = MultiModal(\n",
    "    llm, \n",
    "    system_prompt=system_prompt,  # ì‹œìŠ¤í…œ ì—­í•  ì •ì˜\n",
    "    user_prompt=user_prompt       # ì‚¬ìš©ì ìš”ì²­ ì •ì˜\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51735d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ì„í•  ì¬ë¬´ì œí‘œ ì´ë¯¸ì§€ URL\n",
    "IMAGE_PATH_FROM_FILE = \"https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png\"\n",
    "\n",
    "# ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ëœ ë©€í‹°ëª¨ë‹¬ LLMìœ¼ë¡œ ì¬ë¬´ì œí‘œ ë¶„ì„\n",
    "answer = multimodal_llm_with_prompt.stream(IMAGE_PATH_FROM_FILE)\n",
    "\n",
    "# ì¬ë¬´ì œí‘œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
