{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "z52x0tivhe",
   "metadata": {},
   "source": [
    "# 🤖 OpenAI ChatGPT API와 LangChain 활용 완전 가이드\n",
    "\n",
    "## 📚 개요\n",
    "\n",
    "이 튜토리얼에서는 **OpenAI의 ChatGPT API**를 **LangChain 프레임워크**와 함께 활용하는 방법을 단계별로 학습합니다. \n",
    "\n",
    "### 🎯 학습 목표\n",
    "\n",
    "- **LangChain**과 **LCEL(LangChain Expression Language)** 기본 개념 이해\n",
    "- **ChatOpenAI** 클래스 활용법 완전 정복\n",
    "- **다양한 모델 옵션**과 **설정 방법** 이해\n",
    "- **멀티모달(이미지 인식)** 기능 활용\n",
    "- **스트리밍** 및 **프롬프트 엔지니어링** 실습\n",
    "\n",
    "### 📖 목차\n",
    "\n",
    "1. **🛠️ 환경 설정** - 기본 설정 및 LangSmith 연동\n",
    "2. **🚀 LangChain과 LCEL 기본 개념** - 핵심 개념 이해\n",
    "3. **🤖 ChatOpenAI 기본 사용법** - 객체 생성과 기본 질의\n",
    "4. **📊 응답 구조 이해** - AI 메시지 형태와 메타데이터\n",
    "5. **🎯 고급 기능** - LogProb, 스트리밍, 멀티모달\n",
    "6. **✨ 프롬프트 엔지니어링** - System/User 프롬프트 활용\n",
    "\n",
    "### 💡 사전 준비사항\n",
    "\n",
    "- OpenAI API 키 발급 및 환경변수 설정\n",
    "- Python 가상환경 구성 완료\n",
    "- 기본적인 Python 문법 이해\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf28f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# .env 파일에 LANGCHAIN_API_KEY를 입력합니다.\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LangChain-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4xwrsfd5d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🚀 LangChain과 LCEL 기본 개념\n",
    "\n",
    "### 🔗 LangChain이란?\n",
    "\n",
    "**LangChain**은 Large Language Model(LLM)을 활용한 애플리케이션 개발을 위한 **통합 프레임워크**입니다. \n",
    "\n",
    "#### 🏗️ LangChain의 핵심 가치\n",
    "\n",
    "- **🔧 표준화**: 다양한 LLM을 동일한 인터페이스로 사용\n",
    "- **⚡ 효율성**: 복잡한 AI 워크플로우를 간단한 코드로 구현\n",
    "- **🔄 재사용성**: 한 번 만든 컴포넌트를 다양한 곳에 활용\n",
    "- **🛠️ 확장성**: 필요에 따라 기능을 쉽게 추가/변경\n",
    "\n",
    "### ⚗️ LCEL(LangChain Expression Language)\n",
    "\n",
    "**LCEL**은 LangChain 컴포넌트들을 **체인처럼 연결**하는 강력한 문법입니다.\n",
    "\n",
    "#### 🎯 LCEL의 특징\n",
    "\n",
    "```python\n",
    "# 전통적인 방식\n",
    "def traditional_approach(input_text):\n",
    "    prompt_result = prompt.format(input=input_text)\n",
    "    llm_result = llm.invoke(prompt_result)\n",
    "    output_result = output_parser.parse(llm_result)\n",
    "    return output_result\n",
    "\n",
    "# LCEL 방식 - 간결하고 명확!\n",
    "chain = prompt | llm | output_parser\n",
    "result = chain.invoke({\"input\": input_text})\n",
    "```\n",
    "\n",
    "#### ✨ LCEL의 장점\n",
    "\n",
    "- **📖 가독성**: 처리 흐름을 한눈에 파악 가능\n",
    "- **⚡ 병렬 처리**: 자동으로 최적화된 실행\n",
    "- **🔄 스트리밍**: 실시간 결과 출력 지원\n",
    "- **🛡️ 오류 처리**: 강력한 예외 처리 메커니즘\n",
    "\n",
    "### 💻 실제 활용 예시\n",
    "\n",
    "```python\n",
    "# 프롬프트 → LLM → 결과 파싱의 연쇄 작업\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 각 컴포넌트 정의\n",
    "prompt = ChatPromptTemplate.from_template(\"Explain {topic} in simple terms\")\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# LCEL로 체인 구성\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 한 번의 호출로 전체 과정 실행\n",
    "result = chain.invoke({\"topic\": \"artificial intelligence\"})\n",
    "```\n",
    "\n",
    "이제 실제 **ChatOpenAI** 클래스를 활용해보겠습니다! 🎯\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550920c-09d8-48b3-be2f-b36362c37989",
   "metadata": {},
   "source": [
    "## 🤖 ChatOpenAI - OpenAI 모델의 LangChain 인터페이스\n",
    "\n",
    "**ChatOpenAI**는 OpenAI의 강력한 언어 모델들을 LangChain에서 쉽게 사용할 수 있도록 해주는 **통합 인터페이스**입니다.\n",
    "\n",
    "### 🎯 주요 설정 옵션들\n",
    "\n",
    "#### 🌡️ **temperature** (창의성 조절)\n",
    "```python\n",
    "temperature=0.1  # 일관되고 정확한 답변 (사실 질문에 적합)\n",
    "temperature=0.8  # 창의적이고 다양한 답변 (창작 활동에 적합)\n",
    "```\n",
    "- **범위**: 0.0 ~ 2.0\n",
    "- **낮은 값 (0.0~0.3)**: 정확하고 일관된 답변, 팩트 체크에 최적\n",
    "- **중간 값 (0.4~0.7)**: 균형잡힌 답변, 일반적인 대화에 적합  \n",
    "- **높은 값 (0.8~2.0)**: 창의적이고 예측 불가능한 답변, 브레인스토밍에 유용\n",
    "\n",
    "#### 📏 **max_tokens** (최대 출력 길이)\n",
    "```python\n",
    "max_tokens=2048  # 최대 2048개 토큰까지 생성\n",
    "```\n",
    "- **토큰이란?** 단어의 일부분 또는 전체 (한국어 1토큰 ≈ 2-3글자)\n",
    "- **비용 절약 팁**: 필요한 만큼만 설정하여 API 비용 최적화\n",
    "\n",
    "#### 🏷️ **model_name** (사용할 모델)\n",
    "- **GPT-4.1**: 최신 고성능 모델, 복잡한 추론과 멀티모달 지원\n",
    "- **GPT-4.1-mini**: 성능과 비용의 균형, 일반적인 작업에 최적\n",
    "- **GPT-4.1-nano**: 빠르고 저렴한 모델, 간단한 작업에 적합\n",
    "\n",
    "### 📊 OpenAI 모델 비교표\n",
    "\n",
    "| 모델 계열       | 모델명 (API Name) | 입력       | 컨텍스트 윈도우  | 최대 출력 토큰 | 지식 마감일 (Cutoff) | 가격 (1M토큰당)                  |\n",
    "| :---------- | :------------- | :------- | :-------- | :------- | :-------------- | :------------------------------ |\n",
    "| **GPT-5** ⭐   | `gpt-5`        | 텍스트, 이미지 | 400,000   | 128,000  | 2024년 9월 30일    | **입력:** $1.25<br>**출력:** $10.00 |\n",
    "|             | `gpt-5-mini`   | 텍스트, 이미지 | 400,000   | 128,000  | 2024년 5월 31일    | **입력:** $0.25<br>**출력:** $2.00  |\n",
    "|             | `gpt-5-nano`   | 텍스트, 이미지 | 400,000   | 128,000  | 2024년 5월 31일    | **입력:** $0.05<br>**출력:** $0.40  |\n",
    "| **GPT-4.1** 🚀 | `gpt-4.1`      | 텍스트, 이미지 | 1,047,576 | 32,768   | 2024년 6월 1일     | **입력:** $2.00<br>**출력:** $8.00  |\n",
    "|             | `gpt-4.1-mini` | 텍스트, 이미지 | 1,047,576 | 32,768   | 2024년 6월 1일     | **입력:** $0.40<br>**출력:** $1.60  |\n",
    "|             | `gpt-4.1-nano` | 텍스트, 이미지 | 1,047,576 | 32,768   | 2024년 6월 1일     | **입력:** $0.10<br>**출력:** $0.40  |\n",
    "| **GPT-4o**  📷  | `gpt-4o`       | 텍스트, 이미지 | 128,000   | 16,384   | 2023년 10월 1일    | **입력:** $2.50<br>**출력:** $10.00 |\n",
    "|             | `gpt-4o-mini`  | 텍스트, 이미지 | 128,000   | 16,384   | 2023년 10월 1일    | **입력:** $0.15<br>**출력:** $0.60  |\n",
    "\n",
    "![OpenAI Models Comparison](./images/gpt-models3-202508.png)\n",
    "\n",
    "### 💡 모델 선택 가이드\n",
    "\n",
    "- **🎯 정확성 우선**: `gpt-4.1` - 복잡한 분석, 전문적 작업\n",
    "- **⚡ 균형잡힌 선택**: `gpt-4.1-mini` - 일반적인 용도, 가성비 최고\n",
    "- **💰 비용 절약**: `gpt-4.1-nano` - 간단한 질답, 대량 처리\n",
    "\n",
    "> **참고 링크**: [OpenAI 공식 모델 문서](https://platform.openai.com/docs/models)\n",
    "\n",
    "### 🚀 기본 사용법\n",
    "\n",
    "이제 실제로 ChatOpenAI를 사용해보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc161c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0) - 낮을수록 일관된 답변\n",
    "    model_name=\"gpt-4.1\",  # 사용할 OpenAI 모델명\n",
    ")\n",
    "\n",
    "# 사용자 질의내용 정의\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# LLM에 질의하고 결과 출력\n",
    "print(f\"[답변]: {llm.invoke(question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ef2647",
   "metadata": {},
   "source": [
    "### 📊 응답 구조 이해하기 - AIMessage 객체\n",
    "\n",
    "ChatOpenAI의 응답은 단순한 텍스트가 아닌 **AIMessage 객체**로 반환됩니다. 이 객체에는 다양한 유용한 정보가 담겨있습니다!\n",
    "\n",
    "#### 🔍 AIMessage의 구성 요소\n",
    "\n",
    "- **💬 content**: 실제 AI가 생성한 텍스트 답변\n",
    "- **📊 response_metadata**: 토큰 사용량, 모델 정보, 처리 시간 등의 메타데이터\n",
    "- **🏷️ 기타 정보**: 메시지 ID, 타입 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af58a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 질의내용 정의\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# LLM에 질의하고 응답 객체를 변수에 저장\n",
    "response = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 응답 객체 확인 (AIMessage 형태)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd49c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 응답 내용만 텍스트로 추출\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df69214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 응답 메타데이터 확인 (토큰 사용량, 모델 정보 등)\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4a51a",
   "metadata": {},
   "source": [
    "### 🎯 LogProb - AI의 확신도 측정하기\n",
    "\n",
    "**LogProb(로그 확률)** 은 AI가 각 단어를 선택할 때의 **확신도**를 수치로 보여주는 고급 기능입니다.\n",
    "\n",
    "#### 🤔 LogProb이 유용한 상황들\n",
    "\n",
    "- **📊 답변 신뢰도 평가**: AI가 얼마나 확신하는지 판단\n",
    "- **🔍 품질 관리**: 불확실한 답변을 필터링\n",
    "- **📈 모델 분석**: AI의 의사결정 과정 이해\n",
    "- **⚖️ 여러 답변 비교**: 가장 확실한 답변 선택\n",
    "\n",
    "#### 💡 LogProb 해석 방법\n",
    "\n",
    "- **높은 확률 (-0.1 ~ 0.0)**: AI가 매우 확신하는 답변\n",
    "- **중간 확률 (-2.0 ~ -0.1)**: 일반적인 수준의 확신\n",
    "- **낮은 확률 (-5.0 이하)**: AI가 불확실해하는 답변\n",
    "\n",
    "> **💭 실생활 비유**: 시험에서 답을 고를 때 \"90% 확신\" vs \"50% 확신\"과 같은 개념입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe733438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogProb 기능이 활성화된 ChatOpenAI 객체 생성\n",
    "llm_with_logprob = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 출력 토큰 수\n",
    "    model_name=\"gpt-4.1\",  # 사용할 OpenAI 모델명\n",
    ").bind(logprobs=True)  # 토큰별 확률 정보 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 질의내용 정의\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# LogProb가 활성화된 LLM으로 질의\n",
    "response = llm_with_logprob.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogProb 정보가 포함된 메타데이터 확인\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aec3e6",
   "metadata": {},
   "source": [
    "### ⚡ 스트리밍 출력 - 실시간 응답 체험\n",
    "\n",
    "**스트리밍**은 AI가 답변을 **실시간으로 생성하면서 즉시 보여주는** 기능입니다. 마치 사람이 말하듯이 단어 하나씩 나타나는 것을 볼 수 있습니다!\n",
    "\n",
    "#### 🎯 스트리밍이 유용한 이유\n",
    "\n",
    "- **⏰ 즉시성**: 긴 답변도 기다림 없이 바로 확인\n",
    "- **🔍 투명성**: AI가 어떻게 생각하는지 과정을 관찰\n",
    "- **💬 자연스러움**: 실제 대화하는 듯한 경험\n",
    "- **⚡ 효율성**: 전체 답변 완료를 기다릴 필요 없음\n",
    "\n",
    "#### 💡 활용 시나리오\n",
    "\n",
    "- **📝 긴 글 작성**: 에세이, 보고서 등\n",
    "- **💬 실시간 챗봇**: 대화형 애플리케이션\n",
    "- **🎥 라이브 데모**: 시연이나 발표 시\n",
    "- **⏱️ 긴급 질문**: 빠른 피드백이 필요할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 방식으로 LLM에 질의\n",
    "# 실시간으로 토큰이 생성되는 과정을 확인할 수 있음\n",
    "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a90e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 응답을 실시간으로 출력\n",
    "# 각 토큰이 생성될 때마다 즉시 화면에 표시됨\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f079b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# 스트리밍 방식으로 LLM에 질의\n",
    "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")\n",
    "\n",
    "# langchain_teddynote의 stream_response 함수로 깔끔하게 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95ce8b",
   "metadata": {},
   "source": [
    "## 📷 멀티모달 AI - 이미지를 읽는 인공지능\n",
    "\n",
    "**멀티모달(Multimodal)** 은 여러 종류의 데이터를 동시에 처리할 수 있는 AI 기술입니다. **텍스트뿐만 아니라 이미지, 오디오, 비디오**까지 이해할 수 있습니다!\n",
    "\n",
    "### 🌈 멀티모달이 처리할 수 있는 데이터 타입\n",
    "\n",
    "- **📝 텍스트**: 문서, 이메일, 웹페이지 등의 글자 정보\n",
    "- **🖼️ 이미지**: 사진, 그래프, 도표, 스크린샷 등의 시각적 정보  \n",
    "- **🎵 오디오**: 음성, 음악, 효과음 등의 청각적 정보\n",
    "- **🎬 비디오**: 동영상, 애니메이션 등 시청각 복합 정보\n",
    "\n",
    "### 🎯 GPT-4.1의 비전(Vision) 기능\n",
    "\n",
    "**GPT-4.1**은 강력한 **이미지 인식 능력**을 갖춘 멀티모달 모델입니다.\n",
    "\n",
    "#### 🔍 이미지 분석 가능한 작업들\n",
    "\n",
    "- **📊 차트/그래프 해석**: 데이터 시각화 분석\n",
    "- **📄 문서 OCR**: 이미지 속 텍스트 추출 및 해석\n",
    "- **🏞️ 장면 설명**: 사진 속 상황과 객체 인식\n",
    "- **📋 표/양식 처리**: 복잡한 테이블 데이터 이해\n",
    "- **🎨 창작물 분석**: 그림, 디자인 요소 해석\n",
    "\n",
    "#### 💼 실제 비즈니스 활용 사례\n",
    "\n",
    "- **📈 재무제표 분석**: 복잡한 회계 자료 자동 해석\n",
    "- **🏥 의료 영상 검토**: X-ray, MRI 이미지 보조 분석\n",
    "- **🏗️ 건축 도면 검토**: 설계도 및 시공 현황 파악\n",
    "- **📦 제품 관리**: 상품 사진을 통한 품질 검사\n",
    "\n",
    "> **🚀 혁신 포인트**: 이제 \"이 이미지에서 뭐가 보이나요?\"가 아니라 \"이 재무제표의 핵심 인사이트는 무엇인가요?\"까지 질문할 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.models import MultiModal\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# 기본 ChatOpenAI 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4.1\",  # 이미지 인식이 가능한 모델\n",
    ")\n",
    "\n",
    "# 멀티모달(이미지 + 텍스트 처리) 객체 생성\n",
    "multimodal_llm = MultiModal(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹상의 이미지 URL 정의\n",
    "IMAGE_URL = \"https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg\"\n",
    "\n",
    "# 웹 이미지를 직접 분석하여 스트리밍 응답 생성\n",
    "answer = multimodal_llm.stream(IMAGE_URL)\n",
    "\n",
    "# 실시간으로 이미지 분석 결과 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ec2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬 저장된 이미지 파일 경로 정의\n",
    "IMAGE_PATH_FROM_FILE = \"./images/sample-image.png\"\n",
    "\n",
    "# 로컬 이미지 파일을 분석하여 스트리밍 응답 생성\n",
    "answer = multimodal_llm.stream(IMAGE_PATH_FROM_FILE)\n",
    "\n",
    "# 실시간으로 이미지 분석 결과 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5fc02",
   "metadata": {},
   "source": [
    "## ✨ 프롬프트 엔지니어링 - AI의 역할과 행동 설계\n",
    "\n",
    "**프롬프트 엔지니어링**은 AI가 원하는 방식으로 동작하도록 **정확한 지시사항을 설계**하는 기술입니다. 마치 전문가를 고용할 때 **업무 설명서**를 작성하는 것과 같습니다!\n",
    "\n",
    "### 🎭 System Prompt vs User Prompt\n",
    "\n",
    "#### 👨‍💼 **System Prompt** - AI의 정체성과 역할 정의\n",
    "```python\n",
    "system_prompt = \"You are a professional financial analyst...\"\n",
    "```\n",
    "- **목적**: AI가 **누구인지, 어떤 전문성을 가져야 하는지** 정의\n",
    "- **특징**: 전체 대화 세션 동안 지속되는 **기본 설정**\n",
    "- **예시**: \"당신은 친절한 고객 서비스 직원입니다\", \"당신은 전문 의료진입니다\"\n",
    "\n",
    "#### 🗣️ **User Prompt** - 구체적인 작업 지시사항\n",
    "```python\n",
    "user_prompt = \"Please analyze the financial data and provide insights...\"\n",
    "```\n",
    "- **목적**: **구체적으로 무엇을 해야 하는지** 상세한 작업 명령\n",
    "- **특징**: 각 요청마다 달라질 수 있는 **가변적 지시사항**\n",
    "- **예시**: \"이 문서를 요약해주세요\", \"3가지 대안을 제시해주세요\"\n",
    "\n",
    "### 🎯 효과적인 프롬프트 작성 원칙\n",
    "\n",
    "#### 1️⃣ **명확성 (Clarity)**\n",
    "```python\n",
    "# ❌ 애매한 지시\n",
    "\"재무제표를 봐주세요\"\n",
    "\n",
    "# ✅ 명확한 지시  \n",
    "\"재무제표의 수익성 지표를 분석하고 3가지 핵심 인사이트를 제시해주세요\"\n",
    "```\n",
    "\n",
    "#### 2️⃣ **구체성 (Specificity)**\n",
    "```python\n",
    "# ❌ 추상적 요청\n",
    "\"도움을 주세요\"\n",
    "\n",
    "# ✅ 구체적 요청\n",
    "\"매출 증감 원인을 분석하고, 향후 3개월 예측과 개선 방안을 제시해주세요\"\n",
    "```\n",
    "\n",
    "#### 3️⃣ **맥락 제공 (Context)**\n",
    "```python\n",
    "# ✅ 풍부한 맥락\n",
    "\"당신은 10년 경력의 재무 분석 전문가입니다. 중소기업 CEO를 대상으로 복잡한 재무 용어는 쉽게 설명해주세요.\"\n",
    "```\n",
    "\n",
    "### 💡 프롬프트 엔지니어링의 실제 효과\n",
    "\n",
    "좋은 프롬프트는 **AI의 성능을 10배 이상 향상**시킬 수 있습니다:\n",
    "\n",
    "- **🎯 정확도 향상**: 원하는 답변을 더 정확하게 생성\n",
    "- **📊 일관성 보장**: 매번 비슷한 품질의 결과 제공  \n",
    "- **⚡ 효율성 증대**: 반복 질문과 수정 작업 최소화\n",
    "- **🔧 커스터마이징**: 특정 업무나 스타일에 맞춤 조정\n",
    "\n",
    "이제 실제 재무제표 분석에 특화된 프롬프트를 만들어보겠습니다! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be092af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 프롬프트: AI의 역할과 행동 방식을 정의\n",
    "system_prompt = \"\"\"You are a professional financial AI assistant specialized in analyzing financial statements and tables. \n",
    "Your mission is to interpret given tabular financial data and provide insightful, interesting findings in a friendly and helpful manner. \n",
    "Focus on key metrics, trends, and notable patterns that would be valuable for business analysis.\"\"\"\n",
    "\n",
    "# 사용자 프롬프트: 구체적인 작업 지시사항\n",
    "user_prompt = \"\"\"Please analyze the financial statement provided in the image. \n",
    "Identify and summarize the most interesting and important findings, including key financial metrics, trends, and insights that would be valuable for business decision-making.\"\"\"\n",
    "\n",
    "# 커스텀 프롬프트가 적용된 멀티모달 객체 생성\n",
    "multimodal_llm_with_prompt = MultiModal(\n",
    "    llm, \n",
    "    system_prompt=system_prompt,  # 시스템 역할 정의\n",
    "    user_prompt=user_prompt       # 사용자 요청 정의\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51735d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석할 재무제표 이미지 URL\n",
    "IMAGE_PATH_FROM_FILE = \"https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png\"\n",
    "\n",
    "# 커스텀 프롬프트가 적용된 멀티모달 LLM으로 재무제표 분석\n",
    "answer = multimodal_llm_with_prompt.stream(IMAGE_PATH_FROM_FILE)\n",
    "\n",
    "# 재무제표 분석 결과를 실시간으로 출력\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
