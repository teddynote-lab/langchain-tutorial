{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📝 PromptTemplate 완전 정복 가이드\n",
    "\n",
    "## 📚 개요\n",
    "\n",
    "**PromptTemplate** 은 AI에게 지시를 내릴 때 사용하는 **템플릿 시스템** 입니다! 마치 **편지 양식** 처럼 미리 틀을 만들어두고, 필요한 부분만 바꿔서 사용할 수 있어요. 🎯\n",
    "\n",
    "### 🏗️ PromptTemplate이 특별한 이유\n",
    "\n",
    "일반적으로 AI에게 질문할 때마다 새롭게 문장을 작성해야 합니다. 하지만 PromptTemplate을 사용하면:\n",
    "\n",
    "- **🔄 재사용성**: 한 번 만든 템플릿을 계속 활용\n",
    "- **🎯 일관성**: 항상 같은 형식으로 질문 가능\n",
    "- **⚡ 효율성**: 매번 새로 작성할 필요 없음\n",
    "- **🛡️ 안정성**: 검증된 프롬프트 패턴 사용\n",
    "\n",
    "### 🎯 이 튜토리얼에서 배울 것들\n",
    "\n",
    "1. **📝 PromptTemplate 기본** - 변수를 사용한 동적 프롬프트 생성\n",
    "2. **📁 파일 기반 템플릿** - YAML 파일로 프롬프트 관리하기\n",
    "3. **💬 ChatPromptTemplate** - 대화형 AI를 위한 특별한 템플릿\n",
    "4. **🔄 MessagePlaceholder** - 동적인 대화 내역 관리\n",
    "\n",
    "### 🎮 실생활 비유로 이해하기\n",
    "\n",
    "**PromptTemplate** 을 **이메일 템플릿** 에 비유해보세요:\n",
    "\n",
    "```\n",
    "📧 일반적인 방법 (매번 새로 작성)\n",
    "안녕하세요, 김철수님\n",
    "오늘 회의 일정을 알려드립니다...\n",
    "\n",
    "📋 TemplateTemplate 방법 (틀 활용)\n",
    "안녕하세요, {이름}님\n",
    "{날짜} {일정} 을 알려드립니다...\n",
    "```\n",
    "\n",
    "### 💡 핵심 개념\n",
    "\n",
    "> **\\\"한 번 만들어두면 계속 사용할 수 있는 똑똑한 질문 틀\\\"**\n",
    "> \n",
    "> _변수만 바꿔주면 다양한 상황에 맞는 프롬프트 완성!_ ✨\n",
    "\n",
    "### 🚀 준비되셨나요?\n",
    "\n",
    "이제 실제 예제를 통해 PromptTemplate의 강력한 기능을 체험해봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 🛠️\n",
    "\n",
    "PromptTemplate 기능을 체험하기 전에 필요한 도구들을 준비해봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: PromptTemplate 기본 🌟\n",
    "\n",
    "## 1.1 LLM 모델 준비하기\n",
    "\n",
    "PromptTemplate을 사용하기 전에 먼저 **AI 모델을 준비** 해야 합니다. 마치 **편지를 받을 사람을 정하는 것** 과 같아요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI의 ChatGPT 모델을 불러옵니다\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 객체를 생성합니다 (gpt-4.1 모델 사용)\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 PromptTemplate 기본 사용법 📝\n",
    "\n",
    "### 🎯 변수를 사용한 동적 프롬프트\n",
    "\n",
    "**PromptTemplate** 의 핵심은 **변수** 를 사용하는 것입니다! 마치 **Mad Libs 게임** 처럼 빈 칸에 원하는 단어를 넣어서 문장을 완성할 수 있어요.\n",
    "\n",
    "#### 📋 기본 문법\n",
    "- 변수는 `{변수명}` 형태로 정의합니다\n",
    "- `from_template()` 메소드로 템플릿을 생성합니다\n",
    "- `format()` 메소드로 변수에 값을 대입합니다\n",
    "\n",
    "### 🏠 실생활 예시로 이해하기\n",
    "\n",
    "일반적인 방법:\n",
    "```\n",
    "\"대한민국의 수도는 어디인가요?\"\n",
    "\"일본의 수도는 어디인가요?\" \n",
    "\"프랑스의 수도는 어디인가요?\"\n",
    "```\n",
    "\n",
    "PromptTemplate 방법:\n",
    "```\n",
    "\"{country}의 수도는 어디인가요?\"\n",
    "```\n",
    "\n",
    "**하나의 템플릿** 으로 **무한한 질문** 을 만들 수 있습니다! ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PromptTemplate 클래스를 불러옵니다\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 템플릿 문자열을 정의합니다. {country}는 나중에 값이 들어갈 변수입니다\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 사용하여 PromptTemplate 객체를 생성합니다\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔄 변수에 값 대입하기\n",
    "\n",
    "이제 `{country}` 변수에 실제 **국가명을 대입** 해서 완전한 질문을 만들어보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 메소드를 사용하여 {country} 변수에 \"대한민국\" 값을 대입합니다\n",
    "prompt = prompt.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 템플릿을 정의합니다\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# PromptTemplate 객체를 생성합니다\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 파이프라인(체인)을 생성합니다: 프롬프트 → LLM\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 실행합니다: \"대한민국\"이 {country} 변수에 자동으로 대입됩니다\n",
    "result = chain.invoke({\"country\": \"대한민국\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: 파일 기반 템플릿 관리 📁\n",
    "\n",
    "## 2.1 왜 파일로 관리할까? 🤔\n",
    "\n",
    "코드 안에 프롬프트를 직접 작성하는 것보다 **별도 파일로 관리하는 것** 이 훨씬 효율적입니다!\n",
    "\n",
    "### 🏢 기업에서 사용하는 방식\n",
    "\n",
    "실제 프로덕션 환경에서는 다음과 같은 이유로 파일 기반 관리를 선호합니다:\n",
    "\n",
    "- **👥 협업**: 개발자가 아닌 사람도 프롬프트 수정 가능\n",
    "- **🔄 버전 관리**: Git으로 프롬프트 변경 이력 추적\n",
    "- **🌍 다국어**: 언어별로 다른 프롬프트 파일 관리\n",
    "- **🎯 재사용**: 여러 프로젝트에서 같은 템플릿 활용\n",
    "- **📝 유지보수**: 코드 수정 없이 프롬프트만 개선 가능\n",
    "\n",
    "### 📋 YAML 파일 형식의 장점\n",
    "\n",
    "**YAML** 은 사람이 읽고 쓰기 쉬운 데이터 형식입니다:\n",
    "\n",
    "```yaml\n",
    "_type: prompt\n",
    "input_variables: [\"fruit\"]\n",
    "template: \"What color is {fruit}?\"\n",
    "```\n",
    "\n",
    "간단하고 깔끔하죠? ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_prompt 함수를 불러옵니다\n",
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "# YAML 파일에서 프롬프트 템플릿을 로드합니다\n",
    "prompt = load_prompt(\"prompts/fruit_color.yaml\", encoding=\"utf-8\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로드된 템플릿에 값을 대입해서 결과를 확인합니다\n",
    "prompt.format(fruit=\"사과\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 YAML 파일도 로드해봅시다\n",
    "prompt2 = load_prompt(\"prompts/capital.yaml\")\n",
    "\n",
    "# 국가 변수에 값을 대입하여 결과를 출력합니다\n",
    "print(prompt2.format(country=\"대한민국\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: ChatPromptTemplate - 대화형 AI의 핵심 💬\n",
    "\n",
    "## 3.1 ChatPromptTemplate이 뭐가 다를까? 🤔\n",
    "\n",
    "일반적인 `PromptTemplate` 은 **단순한 텍스트 질문** 에 적합합니다. 하지만 **ChatGPT 같은 대화형 AI** 와 소통할 때는 **ChatPromptTemplate** 이 훨씬 효과적입니다!\n",
    "\n",
    "### 📱 카카오톡 vs 이메일 비유\n",
    "\n",
    "#### 📧 일반 PromptTemplate (이메일 방식)\n",
    "```\n",
    "\"안녕하세요. 대한민국의 수도가 어디인지 알려주세요.\"\n",
    "```\n",
    "\n",
    "#### 💬 ChatPromptTemplate (대화 방식)\n",
    "```\n",
    "시스템: \"당신은 친절한 지리 전문가입니다.\"\n",
    "사용자: \"안녕하세요!\"\n",
    "AI: \"안녕하세요! 지리에 관해 무엇이든 물어보세요.\"\n",
    "사용자: \"대한민국의 수도는 어디인가요?\"\n",
    "```\n",
    "\n",
    "### 🎯 ChatPromptTemplate의 특별한 기능\n",
    "\n",
    "- **🎭 역할 설정**: 시스템 메시지로 AI의 성격과 역할 정의\n",
    "- **💭 대화 맥락**: 이전 대화 내용을 기억하고 참조\n",
    "- **🔄 연속성**: 자연스러운 대화 흐름 유지\n",
    "- **⚙️ 다양한 메시지 타입**: system, human, ai 역할 구분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 메시지 역할(Role) 완벽 이해하기\n",
    "\n",
    "ChatPromptTemplate에서는 **3가지 주요 역할** 을 사용합니다:\n",
    "\n",
    "#### 🛠️ **\"system\"** - 시스템 설정 메시지\n",
    "- **목적**: AI의 성격, 역할, 행동 방식을 정의\n",
    "- **예시**: \"당신은 친절한 선생님입니다\", \"전문적인 톤으로 답변하세요\"\n",
    "- **특징**: 사용자에게는 보이지 않는 **내부 설정**\n",
    "\n",
    "#### 🙋 **\"human\"** - 사용자 입력 메시지  \n",
    "- **목적**: 실제 사용자가 보내는 질문이나 요청\n",
    "- **예시**: \"안녕하세요!\", \"파이썬이 뭔가요?\"\n",
    "- **특징**: 실제 **대화의 시작점**\n",
    "\n",
    "#### 🤖 **\"ai\"** - AI 답변 메시지\n",
    "- **목적**: AI가 이전에 답변했던 내용 (대화 이력)\n",
    "- **예시**: \"안녕하세요! 무엇을 도와드릴까요?\"  \n",
    "- **특징**: **대화 맥락 유지** 를 위한 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatPromptTemplate 클래스를 불러옵니다\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 간단한 채팅 프롬프트를 생성합니다 (기본적으로 human 역할)\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{country}의 수도는 어디인가요?\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수에 값을 대입하여 최종 프롬프트를 생성합니다\n",
    "chat_prompt.format(country=\"대한민국\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 다중 메시지로 대화 맥락 만들기 🎭\n",
    "\n",
    "이제 **진짜 대화처럼** 여러 메시지를 조합해서 자연스러운 대화 상황을 만들어보겠습니다! \n",
    "\n",
    "### 🎬 영화 시나리오처럼 구성하기\n",
    "\n",
    "영화 시나리오를 쓸 때 **등장인물별로 대사를 구분** 하듯이, ChatPromptTemplate도 **역할별로 메시지를 구성** 할 수 있습니다:\n",
    "\n",
    "```\n",
    "(역할, 대사) 형태의 튜플로 구성\n",
    "(\"system\", \"당신은 친절한 AI 어시스턴트입니다\")\n",
    "(\"human\", \"안녕하세요!\")  \n",
    "(\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatPromptTemplate을 다시 불러옵니다\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 여러 메시지로 구성된 대화 템플릿을 생성합니다\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # (역할, 메시지) 형태의 튜플 리스트\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful AI assistant. Your name is {name}.\",\n",
    "        ),  # 시스템 설정\n",
    "        (\"human\", \"반가워요!\"),  # 사용자 첫 인사\n",
    "        (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),  # AI 응답\n",
    "        (\"human\", \"{user_input}\"),  # 사용자의 실제 질문 (변수)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# format_messages 메소드로 변수들을 대입하여 완전한 대화를 생성합니다\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"테디\", user_input=\"당신의 이름은 무엇입니까?\"\n",
    ")\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚀 생성된 메시지로 즉시 실행하기\n",
    "\n",
    "만들어진 대화 메시지들을 **LLM에 바로 주입** 해서 결과를 받아볼 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 메시지들을 LLM에 직접 전달하여 답변을 받습니다\n",
    "result = llm.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚡ 체인(Chain)으로 더 효율적으로 사용하기\n",
    "\n",
    "매번 `format_messages` → `llm.invoke` 를 반복하는 것보다 **체인으로 연결** 하면 훨씬 편리합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 체인을 실행합니다: 변수들이 자동으로 대입되고 LLM이 답변을 생성합니다\n",
    "result = chain.invoke({\"name\": \"Teddy\", \"user_input\": \"당신의 이름은 무엇입니까?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 실행합니다: 변수들이 자동으로 대입되고 LLM이 답변을 생성합니다\n",
    "result = chain.invoke({\"name\": \"Teddy\", \"user_input\": \"당신의 이름은 무엇입니까?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: MessagePlaceholder - 유연한 대화 관리 🔄\n",
    "\n",
    "## 4.1 MessagePlaceholder가 필요한 이유 🤔\n",
    "\n",
    "지금까지는 **고정된 대화 패턴** 을 만들었습니다. 하지만 실제 상황에서는 **대화의 길이나 내용이 매번 달라집니다**. 이럴 때 **MessagePlaceholder** 가 진가를 발휘합니다!\n",
    "\n",
    "### 🎭 연극 무대 비유\n",
    "\n",
    "일반적인 ChatPromptTemplate은 **대본이 정해진 연극** 과 같습니다:\n",
    "\n",
    "```\n",
    "배우A: \"안녕하세요!\"  \n",
    "배우B: \"반가워요!\"  \n",
    "배우A: \"오늘 날씨가 좋네요\"\n",
    "```\n",
    "\n",
    "MessagePlaceholder는 **즉흥 연극** 과 같습니다:\n",
    "\n",
    "```\n",
    "배우A: \"안녕하세요!\"  \n",
    "[여기에 자유로운 대화 삽입]  ← MessagePlaceholder\n",
    "배우A: \"그럼 이제 정리해볼까요?\"\n",
    "```\n",
    "\n",
    "### 🔧 MessagePlaceholder의 특별한 기능\n",
    "\n",
    "- **📏 가변 길이**: 대화가 짧을 수도, 길 수도 있음\n",
    "- **🎯 동적 삽입**: 실행 시점에 대화 내용 결정  \n",
    "- **🔄 재사용성**: 다양한 상황에서 같은 템플릿 활용\n",
    "- **🧩 유연성**: 기존 템플릿 구조를 유지하면서 일부만 변경\n",
    "\n",
    "### 💡 언제 사용할까?\n",
    "\n",
    "- **📚 대화 요약**: 길이가 다른 대화들을 요약할 때\n",
    "- **🤖 챗봇**: 이전 대화 이력을 참고해야 할 때  \n",
    "- **📋 회의록**: 참석자와 내용이 매번 다를 때\n",
    "- **🎓 교육**: 학습자별로 다른 질문 패턴이 필요할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 클래스들을 불러옵니다\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# MessagePlaceholder를 포함한 채팅 프롬프트를 생성합니다\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # 시스템 메시지: AI의 역할을 정의합니다\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a summarization expert AI assistant. Your task is to summarize conversations using key keywords.\",\n",
    "        ),\n",
    "        # 가변적인 대화 내용이 들어갈 자리를 만듭니다\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        # 마지막 인간 메시지: 요약 지시사항\n",
    "        (\"human\", \"지금까지의 대화를 {word_count} 단어로 요약합니다.\"),\n",
    "    ]\n",
    ")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧪 MessagePlaceholder 동작 테스트\n",
    "\n",
    "`conversation` 변수에 **실제 대화 목록을 나중에 추가** 할 수 있습니다. 이것이 MessagePlaceholder의 핵심 기능입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 실행을 위한 체인을 생성합니다 (StrOutputParser 추가로 문자열 결과만 받기)\n",
    "chain = chat_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 실행하여 대화를 요약합니다\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"word_count\": 5,  # 5단어로 요약\n",
    "        \"conversation\": [  # 요약할 대화 내용\n",
    "            (\n",
    "                \"human\",\n",
    "                \"안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\",\n",
    "            ),\n",
    "            (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(f\"요약 결과: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
