{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PromptTemplate 튜토리얼\n",
                "\n",
                "## 개요\n",
                "**PromptTemplate** 은 AI 모델에 전달할 프롬프트를 **변수화된 템플릿** 형태로 정의·재사용하기 위한 도구입니다. 반복 작업을 줄이고, 형식을 표준화하며, 협업과 유지보수를 쉽게 합니다.\n",
                "\n",
                "## 학습 목표\n",
                "- **PromptTemplate 기본**: 변수 기반 템플릿 작성과 포맷팅\n",
                "- **파일 기반 템플릿 관리**: YAML로 프롬프트를 분리·버전관리\n",
                "- **ChatPromptTemplate**: 역할 기반 대화 프롬프트 구성\n",
                "- **MessagePlaceholder**: 대화 이력(가변 길이) 삽입\n",
                "\n",
                "## 왜 사용하는가\n",
                "| 장점 | 설명 |\n",
                "|---|---|\n",
                "| **재사용성** | 한 번 정의한 템플릿을 여러 입력에 반복 사용 |\n",
                "| **일관성** | 팀/서비스 전반에서 동일한 질의 형식 유지 |\n",
                "| **효율성** | 매번 문장을 새로 작성하지 않아 작업 시간 절감 |\n",
                "| **안정성** | 검증된 프롬프트 패턴을 표준으로 채택 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 환경 설정\n",
                "- `.env` 파일을 사용해 API 키를 관리합니다.\n",
                "- LangSmith 트레이싱을 프로젝트 수준으로 활성화합니다(선택).\n",
                "- OpenRouter 경유로 ChatOpenAI를 사용합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# API KEY 구성 및 LangSmith 설정\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# .env 로드\n",
                "load_dotenv(override=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set LangSmith trace https://smith.langchain.com\n",
                "# Add LANGCHAIN_API_KEY in .env file\n",
                "from langchain_teddynote import logging\n",
                "\n",
                "# 프로젝트명 설정\n",
                "logging.langsmith(\"LangChain-Tutorial\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PromptTemplate 기본\n",
                "\n",
                "### LLM 모델 준비\n",
                "PromptTemplate을 사용하려면 우선 대화 모델(LLM)을 구성합니다. 본 튜토리얼은 OpenRouter를 통해 OpenAI 계열 모델을 호출합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# OpenRouter 경유로 ChatOpenAI 구성\n",
                "import os\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "# Create ChatOpenAI object\n",
                "llm = ChatOpenAI(\n",
                "    temperature=0.1,\n",
                "    model=\"openai/gpt-4.1\",\n",
                "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
                "    base_url=os.getenv(\"OPENROUTER_BASE_URL\"),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PromptTemplate 기본 사용법\n",
                "\n",
                "### 핵심 문법\n",
                "\n",
                "- 변수 표기: `{변수명}`\n",
                "\n",
                "- 템플릿 생성: `PromptTemplate.from_template(...)`\n",
                "- 값 대입: `format(...)` 또는 체인에서 매핑 입력\n",
                "\n",
                "### 예시\n",
                "\n",
                "일반적인 방법:\n",
                "```\n",
                "\"대한민국의 수도는 어디인가요?\"\n",
                "\"일본의 수도는 어디인가요?\" \n",
                "\"프랑스의 수도는 어디인가요?\"\n",
                "```\n",
                "\n",
                "PromptTemplate 방법:\n",
                "```\n",
                "\"{country}의 수도는 어디인가요?\"\n",
                "```\n",
                "\n",
                "템플릿을 사용하면 동일한 형식을 유지하면서 여러 입력값에 쉽게 재사용할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PromptTemplate 클래스를 불러옵니다\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "\n",
                "# 템플릿 문자열을 정의합니다. {country}는 나중에 값이 들어갈 변수입니다\n",
                "template = \"{country}의 수도는 어디인가요?\"\n",
                "\n",
                "# from_template 메소드를 사용하여 PromptTemplate 객체를 생성합니다\n",
                "prompt = PromptTemplate.from_template(template)\n",
                "prompt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 변수에 값 대입하기\n",
                "`{country}` 변수에 실제 값을 넣어 최종 프롬프트를 생성합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# format 메소드를 사용하여 {country} 변수에 \"대한민국\" 값을 대입합니다\n",
                "prompt = prompt.format(country=\"대한민국\")\n",
                "prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 새로운 템플릿을 정의합니다\n",
                "template = \"{country}의 수도는 어디인가요?\"\n",
                "\n",
                "# PromptTemplate 객체를 생성합니다\n",
                "prompt = PromptTemplate.from_template(template)\n",
                "\n",
                "# 파이프라인(체인)을 생성합니다: 프롬프트 → LLM\n",
                "chain = prompt | llm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 체인을 실행합니다: \"대한민국\"이 {country} 변수에 자동으로 대입됩니다\n",
                "result = chain.invoke({\"country\": \"대한민국\"})\n",
                "print(result.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 파일 기반 템플릿 관리\n",
                "\n",
                "### 왜 파일로 관리하나\n",
                "\n",
                "코드와 프롬프트를 분리하면 협업과 변경 관리가 쉬워집니다.\n",
                "\n",
                "### 활용상의 장점\n",
                "\n",
                "실제 프로덕션 환경에서는 다음과 같은 이유로 파일 기반 관리를 선호합니다:\n",
                "\n",
                "- **협업**: 비개발자도 YAML만 수정하여 참여 가능\n",
                "- **버전 관리**: Git으로 변경 이력 추적 용이\n",
                "- **다국어/재사용**: 언어·프로젝트별 템플릿 분리\n",
                "- **유지보수**: 코드 수정 없이 프롬프트 개선 가능\n",
                "\n",
                "## YAML 예시\n",
                "\n",
                "**YAML** 은 사람이 읽고 쓰기 쉬운 데이터 형식입니다:\n",
                "\n",
                "```yaml\n",
                "_type: prompt\n",
                "input_variables: [\"fruit\"]\n",
                "template: \"What color is {fruit}?\"\n",
                "```\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load_prompt 함수를 불러옵니다\n",
                "from langchain_core.prompts import load_prompt\n",
                "\n",
                "# YAML 파일에서 프롬프트 템플릿을 로드합니다\n",
                "prompt = load_prompt(\"prompts/fruit_color.yaml\", encoding=\"utf-8\")\n",
                "prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 로드된 템플릿에 값을 대입해서 결과를 확인합니다\n",
                "prompt.format(fruit=\"사과\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 다른 YAML 파일도 로드해봅시다\n",
                "prompt2 = load_prompt(\"prompts/capital.yaml\")\n",
                "\n",
                "# 국가 변수에 값을 대입하여 결과를 출력합니다\n",
                "print(prompt2.format(country=\"대한민국\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ChatPromptTemplate\n",
                "\n",
                "### ChatPromptTemplate이 뭐가 다를까?\n",
                "\n",
                "일반적인 `PromptTemplate` 은 **단순한 텍스트 질문** 에 적합합니다. 하지만 **ChatGPT 같은 대화형 AI** 와 소통할 때는 **ChatPromptTemplate** 이 훨씬 효과적입니다.\n",
                "\n",
                "#### 일반 PromptTemplate\n",
                "```\n",
                "\"안녕하세요. 대한민국의 수도가 어디인지 알려주세요.\"\n",
                "```\n",
                "\n",
                "#### ChatPromptTemplate\n",
                "```\n",
                "시스템: \"당신은 친절한 지리 전문가입니다.\"\n",
                "사용자: \"안녕하세요!\"\n",
                "AI: \"안녕하세요! 지리에 관해 무엇이든 물어보세요.\"\n",
                "사용자: \"대한민국의 수도는 어디인가요?\"\n",
                "```\n",
                "\n",
                "### ChatPromptTemplate의 특별한 기능\n",
                "\n",
                "- **역할 설정**: 시스템 메시지로 AI의 성격과 역할 정의\n",
                "- **대화 맥락**: 이전 대화 내용을 기억하고 참조\n",
                "- **연속성**: 자연스러운 대화 흐름 유지\n",
                "- **다양한 메시지 타입**: system, human, ai 역할 구분"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ChatPromptTemplate 클래스를 불러옵니다\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "\n",
                "# 간단한 채팅 프롬프트를 생성합니다 (기본적으로 human 역할)\n",
                "chat_prompt = ChatPromptTemplate.from_template(\"{country}의 수도는 어디인가요?\")\n",
                "chat_prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 변수에 값을 대입하여 최종 프롬프트를 생성합니다\n",
                "chat_prompt.format(country=\"대한민국\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 다중 메시지로 맥락 구성\n",
                "\n",
                "역할과 순서를 지정한 메시지 리스트로 실제 대화 상황을 구성하고, 변수로 사용자 입력을 주입할 수 있습니다. \n",
                "\n",
                "#### 구성 형태\n",
                "\n",
                "ChatPromptTemplate은 \"(역할, 메시지)\" 튜플 목록으로 메시지를 정의합니다:\n",
                "\n",
                "```\n",
                "(역할, 대사) 형태의 튜플로 구성\n",
                "(\"system\", \"당신은 친절한 AI 어시스턴트입니다\")\n",
                "(\"human\", \"안녕하세요!\")  \n",
                "(\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\")\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ChatPromptTemplate을 다시 불러옵니다\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "\n",
                "# 여러 메시지로 구성된 대화 템플릿을 생성합니다\n",
                "chat_template = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        # (역할, 메시지) 형태의 튜플 리스트\n",
                "        (\n",
                "            \"system\",\n",
                "            \"You are a helpful AI assistant. Your name is {name}.\",\n",
                "        ),  # 시스템 설정\n",
                "        (\"human\", \"반가워요!\"),  # 사용자 첫 인사\n",
                "        (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),  # AI 응답\n",
                "        (\"human\", \"{user_input}\"),  # 사용자의 실제 질문 (변수)\n",
                "    ]\n",
                ")\n",
                "\n",
                "# format_messages 메소드로 변수들을 대입하여 완전한 대화를 생성합니다\n",
                "messages = chat_template.format_messages(\n",
                "    name=\"테디\", user_input=\"당신의 이름은 무엇입니까?\"\n",
                ")\n",
                "messages"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 생성된 메시지 실행\n",
                "\n",
                "포맷팅된 메시지 목록을 그대로 LLM에 전달해 응답을 확인합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 생성된 메시지들을 LLM에 직접 전달하여 답변을 받습니다\n",
                "result = llm.invoke(messages)\n",
                "print(result.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 체인(Chain)으로 연결\n",
                "\n",
                "프롬프트와 LLM을 파이프(`|`)로 연결하면 입력 매핑과 호출 과정을 단순화할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# chat_template 프롬프트와 llm 모델을 연결하여 체인 생성\n",
                "chain = chat_template | llm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 체인을 실행합니다: 변수들이 자동으로 대입되고 LLM이 답변을 생성합니다\n",
                "result = chain.invoke({\"name\": \"Teddy\", \"user_input\": \"당신의 이름은 무엇입니까?\"})\n",
                "print(result.content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 체인을 실행합니다: 변수들이 자동으로 대입되고 LLM이 답변을 생성합니다\n",
                "chain = chat_template | llm\n",
                "result = chain.invoke({\"name\": \"Teddy\", \"user_input\": \"당신의 이름은 무엇입니까?\"})\n",
                "print(result.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## MessagePlaceholder\n",
                "\n",
                "### 필요성\n",
                "\n",
                "대화 길이와 구성은 상황마다 달라집니다. **MessagePlaceholder** 는 가변 길이의 대화 이력을 한 번에 삽입할 수 있도록 해 줍니다.\n",
                "\n",
                "### 특징\n",
                "\n",
                "- **가변 길이**: 메시지 수와 내용이 유동적이어도 처리 가능\n",
                "- **동적 삽입**: 실행 시점에 대화 배열을 전달\n",
                "- **재사용성**: 템플릿 구조는 유지하고 맥락만 교체\n",
                "\n",
                "### 활용 예\n",
                "- **대화 요약**: 다양한 길이의 대화를 요약\n",
                "- **챗봇**: 이전 대화 이력을 맥락으로 전달\n",
                "- **업무 노트/회의록**: 회차마다 다른 참석자·내용 반영"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 필요한 클래스들을 불러옵니다\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
                "\n",
                "# MessagePlaceholder를 포함한 채팅 프롬프트를 생성합니다\n",
                "chat_prompt = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        # 시스템 메시지: AI의 역할을 정의합니다\n",
                "        (\n",
                "            \"system\",\n",
                "            \"You are a summarization expert AI assistant. Your task is to summarize conversations using key keywords.\",\n",
                "        ),\n",
                "        # 가변적인 대화 내용이 들어갈 자리를 만듭니다\n",
                "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
                "        # 마지막 인간 메시지: 요약 지시사항\n",
                "        (\"human\", \"지금까지의 대화를 {word_count} 단어로 요약합니다.\"),\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### MessagePlaceholder 동작 테스트\n",
                "\n",
                "`conversation` 변수에 대화 메시지 리스트를 실행 시점에 전달합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 최종 실행을 위한 체인을 생성합니다 (StrOutputParser 추가로 문자열 결과만 받기)\n",
                "chain = chat_prompt | llm | StrOutputParser()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 체인을 실행하여 대화를 요약합니다\n",
                "result = chain.invoke(\n",
                "    {\n",
                "        \"word_count\": 5,  # 5단어로 요약\n",
                "        \"conversation\": [  # 요약할 대화 내용\n",
                "            (\n",
                "                \"human\",\n",
                "                \"안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\",\n",
                "            ),\n",
                "            (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
                "        ],\n",
                "    }\n",
                ")\n",
                "print(f\"요약 결과: {result}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
