{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LCEL í•µì‹¬ ê°œë…\n",
                "\n",
                "## íŒŒì´í”„ë¼ì¸(Pipeline)\n",
                "\n",
                "**LCELì˜ í•µì‹¬ì€ íŒŒì´í”„ë¼ì¸ ì—°ì‚°ì `|`** ì…ë‹ˆë‹¤. ì´ëŠ” **Unix íŒŒì´í”„ë¼ì¸**ì—ì„œ ì˜ê°ì„ ë°›ì€ ê°œë…ìœ¼ë¡œ, í•˜ë‚˜ì˜ ì¶œë ¥ì´ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬ë©ë‹ˆë‹¤.\n",
                "\n",
                "#### íŒŒì´í”„ë¼ì¸ íë¦„ ì˜ˆì‹œ\n",
                "\n",
                "LCEL ì€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë™ì‘í•œë‹¤:\n",
                "\n",
                "```python\n",
                "# LCEL ì²´ì¸ êµ¬ì„±\n",
                "chain = prompt_template | model | output_parser\n",
                "#            â†‘              â†‘          â†‘\n",
                "# 1ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ìƒì„± â†’ 2ë‹¨ê³„: ëª¨ë¸ ì¶”ë¡  â†’ 3ë‹¨ê³„: ê²°ê³¼ íŒŒì‹±\n",
                "```\n",
                "\n",
                "### ê¸°ë³¸ ì²´ì¸ì˜ 3ë‹¨ê³„\n",
                "\n",
                "#### PromptTemplate - ì§€ì‹œì‚¬í•­ ì¤€ë¹„\n",
                "- **ì—­í• **: ì‚¬ìš©ì ì…ë ¥ì„ AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜\n",
                "- **ì…ë ¥**: ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ë³€ìˆ˜ë“¤ (`{\"topic\": \"ì¸ê³µì§€ëŠ¥\"}`)\n",
                "- **ì¶œë ¥**: ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´\n",
                "\n",
                "#### Model - AI ì²˜ë¦¬\n",
                "- **ì—­í• **: í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ AIê°€ ë‹µë³€ ìƒì„±\n",
                "- **ì…ë ¥**: í¬ë§·íŒ…ëœ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸\n",
                "- **ì¶œë ¥**: AIMessage ê°ì²´ (ë‚´ìš© + ë©”íƒ€ë°ì´í„°)\n",
                "\n",
                "#### OutputParser - ê²°ê³¼ ì •ë¦¬\n",
                "- **ì—­í• **: AI ì‘ë‹µì„ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜  \n",
                "- **ì…ë ¥**: AIMessage ê°ì²´\n",
                "- **ì¶œë ¥**: ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë˜ëŠ” êµ¬ì¡°í™”ëœ ë°ì´í„°\n",
                "\n",
                "LCEL ì€ ì „ì²´ ê³¼ì •ì„ í•œ ë²ˆì˜ í˜¸ì¶œë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ë‹¨ìˆœí™”í•œë‹¤.\n",
                "\n",
                "---\n",
                "\n",
                "## PromptTemplate ê°œìš”\n",
                "\n",
                "**PromptTemplate** ì€ **ë™ì  í”„ë¡¬í”„íŠ¸** ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. ë§ˆì¹˜ **í¸ì§€ ì–‘ì‹** ì— ì´ë¦„ë§Œ ë°”ê¿”ì„œ ì—¬ëŸ¬ ì‚¬ëŒì—ê²Œ ë³´ë‚´ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# API KEY ì •ë³´ë¡œë“œ\n",
                "load_dotenv(override=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
                "# .env íŒŒì¼ì— LANGCHAIN_API_KEYë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.\n",
                "from langchain_teddynote import logging\n",
                "\n",
                "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
                "logging.langsmith(\"LangChain-Tutorial\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### PromptTemplate ì˜ êµ¬ì„± ìš”ì†Œ\n",
                "\n",
                "**PromptTemplate** ì€ **í…œí”Œë¦¿ ì—”ì§„** ì˜ ì—­í• ì„ í•˜ë©°, ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ **ë™ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±** í•©ë‹ˆë‹¤.\n",
                "\n",
                "#### í•µì‹¬ êµ¬ì„± ìš”ì†Œ\n",
                "\n",
                "1. template: ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì´ ë‹´ê¸´ ë¬¸ìì—´ í…œí”Œë¦¿\n",
                "   ```python\n",
                "   template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
                "   ```\n",
                "\n",
                "2. input_variables: í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ë“¤ì˜ ì´ë¦„ ëª©ë¡\n",
                "   ```python\n",
                "   # ì¤‘ê´„í˜¸ {} ì•ˆì˜ ë³€ìˆ˜ëª…ë“¤ì´ input_variablesê°€ ë¨\n",
                "   # ìœ„ ì˜ˆì‹œì—ì„œëŠ” [\"country\"]ê°€ ìë™ìœ¼ë¡œ ì¶”ì¶œë¨\n",
                "   ```\n",
                "\n",
                "#### í…œí”Œë¦¿ ë³€ìˆ˜ ì‚¬ìš©ë²•\n",
                "\n",
                "- **ì¤‘ê´„í˜¸ `{}`** ì•ˆì— ë³€ìˆ˜ëª… ì‘ì„±\n",
                "- **ì—¬ëŸ¬ ë³€ìˆ˜** ì‚¬ìš© ê°€ëŠ¥: `\"{name}ë‹˜, {city}ì˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?\"`\n",
                "- **ë³€ìˆ˜ëª…ì€ ì˜ë¬¸ìë¡œ ì‹œì‘** , ìˆ«ìì™€ ì–¸ë”ìŠ¤ì½”ì–´ ì‚¬ìš© ê°€ëŠ¥\n",
                "\n",
                "#### from_template ë©”ì„œë“œ\n",
                "\n",
                "```python\n",
                "# ê°„ë‹¨í•œ ë°©ë²• - from_template() ì‚¬ìš©\n",
                "prompt = PromptTemplate.from_template(\"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\")\n",
                "\n",
                "# ì§ì ‘ ìƒì„±\n",
                "prompt = PromptTemplate(\n",
                "    template=\"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\",\n",
                "    input_variables=[\"country\"]\n",
                ")\n",
                "```\n",
                "\n",
                "from_template ì˜ ì¥ì \n",
                "\n",
                "- ìë™ ë³€ìˆ˜ ì¶”ì¶œ: ì¤‘ê´„í˜¸ ì•ˆì˜ ë³€ìˆ˜ë¥¼ ìë™ ì¸ì‹\n",
                "- ê°„ê²°í•œ ì½”ë“œ: í•œ ì¤„ë¡œ í…œí”Œë¦¿ ìƒì„±\n",
                "- ì˜¤ë¥˜ ê°ì†Œ: ë³€ìˆ˜ëª… ì˜¤íƒ€/ëˆ„ë½ ê°€ëŠ¥ì„± ì¶•ì†Œ\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜ì™€ PromptTemplate í´ë˜ìŠ¤ ì„í¬íŠ¸\n",
                "from langchain_teddynote.messages import stream_response\n",
                "from langchain_core.prompts import PromptTemplate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### PromptTemplate ê°ì²´ ìƒì„±\n",
                "\n",
                "`from_template()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ê°„ë‹¨í•˜ê²Œ PromptTemplate ê°ì²´ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë™ì  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ - {country} ë¶€ë¶„ì´ ë³€ìˆ˜ë¡œ ëŒ€ì²´ë¨\n",
                "template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
                "\n",
                "# from_template ë©”ì„œë“œë¥¼ ì´ìš©í•˜ì—¬ PromptTemplate ê°ì²´ ìƒì„±\n",
                "# ì¤‘ê´„í˜¸ ì•ˆì˜ ë³€ìˆ˜ë“¤ì´ ìë™ìœ¼ë¡œ input_variablesë¡œ ì¸ì‹ë¨\n",
                "prompt_template = PromptTemplate.from_template(template)\n",
                "\n",
                "# ìƒì„±ëœ PromptTemplate ê°ì²´ í™•ì¸\n",
                "prompt_template"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í…œí”Œë¦¿ì— êµ¬ì²´ì ì¸ ê°’ì„ ëŒ€ì…í•˜ì—¬ ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
                "prompt = prompt_template.format(country=\"ëŒ€í•œë¯¼êµ­\")\n",
                "print(f\"ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {prompt}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë‹¤ë¥¸ êµ­ê°€ë¡œ ë³€ê²½í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸\n",
                "prompt = prompt_template.format(country=\"ë¯¸êµ­\")\n",
                "print(f\"ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {prompt}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ChatOpenAI ëª¨ë¸ ì„í¬íŠ¸ ë° ì´ˆê¸°í™”\n",
                "from langchain_openai import ChatOpenAI\n",
                "import os\n",
                "\n",
                "# OpenRouter ê¸°ë°˜ ëª¨ë¸ ê°ì²´ ìƒì„±\n",
                "model = ChatOpenAI(\n",
                "    temperature=0.1,\n",
                "    model=\"openai/gpt-4.1\",\n",
                "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
                "    base_url=os.getenv(\"OPENROUTER_BASE_URL\"),\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response = model.invoke(prompt)\n",
                "print(response.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## LCEL ì²´ì¸ ìƒì„±\n",
                "\n",
                "### LCEL(LangChain Expression Language) ì‹¬í™”\n",
                "\n",
                "![LCEL Pipeline](./images/lcel.png)\n",
                "\n",
                "**LCELì˜ í•µì‹¬ì€ `|` (íŒŒì´í”„) ì—°ì‚°ì** ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì—¬ëŸ¬ êµ¬ì„± ìš”ì†Œë¥¼ **ì²´ì¸ì²˜ëŸ¼ ì—°ê²°** í•˜ì—¬ í•˜ë‚˜ì˜ í†µí•©ëœ ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "### íŒŒì´í”„ë¼ì¸ ì—°ì‚°ìì˜ ì‘ë™ ì›ë¦¬\n",
                "\n",
                "```python\n",
                "chain = prompt_template | model | output_parser\n",
                "```\n",
                "\n",
                "#### ë°ì´í„° íë¦„ ê³¼ì •\n",
                "\n",
                "1. ì…ë ¥: `{\"topic\": \"ì¸ê³µì§€ëŠ¥\"}` (ë”•ì…”ë„ˆë¦¬)\n",
                "2. 1ë‹¨ê³„: `prompt_template` â†’ ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸\n",
                "3. 2ë‹¨ê³„: `model` â†’ AIMessage ê°ì²´ (AI ì‘ë‹µ)  \n",
                "4. 3ë‹¨ê³„: `output_parser` â†’ ìµœì¢… í…ìŠ¤íŠ¸ ê²°ê³¼\n",
                "\n",
                "```python\n",
                "# LCEL íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ  \n",
                "chain = prompt | model | parser\n",
                "```\n",
                "\n",
                "ê³µí†µì \n",
                "\n",
                "- ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë°ì´í„° íë¦„\n",
                "- ê° ë‹¨ê³„ì˜ ì¶œë ¥ì´ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥ì´ ë¨\n",
                "- ëª¨ë“ˆí™”: ë‹¨ê³„ë³„ êµì²´/ì¬ì‚¬ìš© ê°€ëŠ¥\n",
                "\n",
                "### LCEL ì¥ì \n",
                "\n",
                "ìë™ ìµœì í™”\n",
                "\n",
                "- ë³‘ë ¬ ì²˜ë¦¬: ê°€ëŠ¥í•œ ë¶€ë¶„ì€ ë™ì‹œì— ì‹¤í–‰\n",
                "- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: ì¤‘ê°„ ê²°ê³¼ì˜ íš¨ìœ¨ì  ê´€ë¦¬\n",
                "- ìŠ¤íŠ¸ë¦¬ë°: ì‹¤ì‹œê°„ ê²°ê³¼ ì¶œë ¥ ì§€ì›\n",
                "\n",
                "ê°œë°œì ì¹œí™”ì \n",
                "\n",
                "- ë¬¸ë²•ì´ ì§ê´€ì ì´ë©° ë°ì´í„° íë¦„ì„ íŒŒì•…í•˜ê¸° ìš©ì´\n",
                "- ë‹¨ê³„ë³„ ê²°ê³¼ ì¶”ì ì´ ì‰¬ì›€\n",
                "- êµ¬ì„±ìš”ì†Œ ì¬ì‚¬ìš©ì´ ìš©ì´\n",
                "\n",
                "ê°„ë‹¨í•œ ì²´ì¸ì„ êµ¬ì„±í•œë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
                "prompt = PromptTemplate.from_template(\"{topic}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
                "\n",
                "# ChatOpenAI ëª¨ë¸ ê°ì²´ ìƒì„±\n",
                "import os\n",
                "\n",
                "model = ChatOpenAI(\n",
                "    temperature=0.1,\n",
                "    model=\"openai/gpt-4.1\",\n",
                "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
                "    base_url=os.getenv(\"OPENROUTER_BASE_URL\"),\n",
                ")\n",
                "\n",
                "# ê¸°ë³¸ ì²´ì¸ êµ¬ì„± (ì¶œë ¥ íŒŒì„œ ì—†ì´) - í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ë§Œ ì—°ê²°\n",
                "chain = prompt | model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### invoke ë©”ì„œë“œ\n",
                "\n",
                "invoke ëŠ” LCEL ì²´ì¸ì„ ì‹¤í–‰í•˜ëŠ” ê¸°ë³¸ ë©”ì„œë“œì´ë‹¤.\n",
                "\n",
                "ì‚¬ìš©ë²•\n",
                "- **ì…ë ¥ í˜•íƒœ**: Python ë”•ì…”ë„ˆë¦¬ `{\"ë³€ìˆ˜ëª…\": \"ê°’\"}`\n",
                "- **ì‹¤í–‰ ë°©ì‹**: ë™ê¸°ì‹ (ê²°ê³¼ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°)\n",
                "- **ë°˜í™˜ê°’**: ì²´ì¸ì˜ ìµœì¢… ì¶œë ¥ (ì¶œë ¥ íŒŒì„œì— ë”°ë¼ ë‹¬ë¼ì§)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì²´ì¸ ì‹¤í–‰ì„ ìœ„í•œ ì…ë ¥ ë”•ì…”ë„ˆë¦¬ ì •ì˜\n",
                "# í‚¤ëŠ” í…œí”Œë¦¿ì˜ ë³€ìˆ˜ëª…ê³¼ ì¼ì¹˜í•´ì•¼ í•¨\n",
                "input = {\"topic\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LCEL ì²´ì¸ ì‹¤í–‰: í”„ë¡¬í”„íŠ¸ ìƒì„± â†’ ëª¨ë¸ ì²˜ë¦¬ â†’ AIMessage ë°˜í™˜\n",
                "# invoke() ë©”ì„œë“œë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í•œ ë²ˆì— ì‹¤í–‰\n",
                "result = chain.invoke(input)\n",
                "\n",
                "# ê²°ê³¼ ì¶œë ¥ (AIMessage ê°ì²´ í˜•íƒœë¡œ ë°˜í™˜ë¨)\n",
                "result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
                "\n",
                "ìŠ¤íŠ¸ë¦¬ë° ì€ ëª¨ë¸ì´ ìƒì„±í•œ í† í°ì„ ìˆœì°¨ì ìœ¼ë¡œ ì „ì†¡í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ í™•ì¸í•˜ëŠ” ë°©ì‹ì´ë‹¤. ê¸´ ì‘ë‹µì—ì„œë„ ëŒ€ê¸° ì‹œê°„ì„ ë‹¨ì¶•í•œë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì²´ì¸ ì‹¤í–‰ - ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µ ìƒì„± ê³¼ì • í™•ì¸\n",
                "answer = chain.stream(input)\n",
                "\n",
                "# langchain_teddynoteì˜ í—¬í¼ í•¨ìˆ˜ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ê¹”ë”í•˜ê²Œ í‘œì‹œ\n",
                "stream_response(answer)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## OutputParser - ì¶œë ¥ í›„ì²˜ë¦¬\n",
                "\n",
                "**OutputParser** ëŠ” AI ì˜ ë³µì¡í•œ ì‘ë‹µì„ **ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜** í•´ì£¼ëŠ” ë§ˆì§€ë§‰ ë‹¨ê³„ì…ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ ì„í¬íŠ¸\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "\n",
                "# StrOutputParser ê°ì²´ ìƒì„± - AIMessageì—ì„œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\n",
                "output_parser = StrOutputParser()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ì™„ì „í•œ ì²´ì¸ êµ¬ì„±\n",
                "\n",
                "ì´ì œ **3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸** ì„ ì™„ì„±í•´ë´…ì‹œë‹¤: **PromptTemplate â†’ Model â†’ OutputParser**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì™„ì „í•œ LCEL ì²´ì¸ êµ¬ì„±: í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ ì¶œë ¥ íŒŒì„œ\n",
                "# ì´ì œ ê²°ê³¼ê°€ AIMessageê°€ ì•„ë‹Œ ìˆœìˆ˜ ë¬¸ìì—´ë¡œ ë°˜í™˜ë¨\n",
                "chain = prompt | model | output_parser"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì™„ì„±ëœ ì²´ì¸ìœ¼ë¡œ invoke ì‹¤í–‰ - ì´ì œ ìˆœìˆ˜ ë¬¸ìì—´ì´ ë°˜í™˜ë¨\n",
                "input = {\"topic\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"}\n",
                "result = chain.invoke(input)\n",
                "\n",
                "# ê²°ê³¼ ì¶œë ¥ (ì´ì œ ë¬¸ìì—´ í˜•íƒœë¡œ ê¹”ë”í•˜ê²Œ ì¶œë ¥ë¨)\n",
                "print(\"=== ì™„ì„±ëœ ì²´ì¸ ê²°ê³¼ ===\")\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì™„ì„±ëœ ì²´ì¸ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰\n",
                "answer = chain.stream(input)\n",
                "\n",
                "print(\"=== ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ===\")\n",
                "# ì‹¤ì‹œê°„ìœ¼ë¡œ ë¬¸ìì—´ì´ ìƒì„±ë˜ëŠ” ê³¼ì •ì„ ê´€ì°°\n",
                "stream_response(answer)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ì‹¤ìŠµ: ì˜ì–´ íšŒí™” íŠœí„° ì˜ˆì œ\n",
                "\n",
                "ì´ì œ ë°°ìš´ ë‚´ìš©ì„ í™œìš©í•´ì„œ **ì‹¤ìš©ì ì¸ ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸** ë¥¼ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤. \n",
                "\n",
                "### í”„ë¡œì íŠ¸ ê°œìš”\n",
                "\n",
                "- **ëª©í‘œ**: ìƒí™©ë³„ ì˜ì–´ íšŒí™” ìƒì„± + í•œê¸€ ë²ˆì—­ ì œê³µ\n",
                "- **íŠ¹ì§•**: ì²´ê³„ì ì¸ í¬ë§·ìœ¼ë¡œ í•™ìŠµ íš¨ê³¼ ê·¹ëŒ€í™”\n",
                "- **í™œìš©**: ë‹¤ì–‘í•œ ìƒí™©ì— ë§ëŠ” ì˜ì–´ í‘œí˜„ í•™ìŠµ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì „ë¬¸ì ì¸ ì˜ì–´ íšŒí™” íŠœí„° í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ê³„\n",
                "template = \"\"\"You are an experienced English conversation teacher with 10 years of expertise.\n",
                "Create practical English conversations for the given situation with Korean translations.\n",
                "Please follow the FORMAT exactly as shown below.\n",
                "\n",
                "#SITUATION:\n",
                "{question}\n",
                "\n",
                "#FORMAT:\n",
                "- English Conversation:\n",
                "- Korean Translation:\n",
                "- Useful Expressions:\n",
                "- Cultural Notes (if applicable):\n",
                "\"\"\"\n",
                "\n",
                "# ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
                "prompt = PromptTemplate.from_template(template)\n",
                "\n",
                "# ChatOpenAI ëª¨ë¸ ê°ì²´ ìƒì„± (OpenRouter ì‚¬ìš©)\n",
                "import os\n",
                "\n",
                "model = ChatOpenAI(\n",
                "    temperature=0.1,\n",
                "    model=\"openai/gpt-4.1\",\n",
                "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
                "    base_url=os.getenv(\"OPENROUTER_BASE_URL\"),\n",
                ")\n",
                "\n",
                "# ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ ìƒì„±\n",
                "output_parser = StrOutputParser()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì˜ì–´ íšŒí™” íŠœí„° ì²´ì¸ êµ¬ì„±\n",
                "# í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ ì¶œë ¥ íŒŒì„œì˜ ì™„ì „í•œ íŒŒì´í”„ë¼ì¸\n",
                "chain = prompt | model | output_parser"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì²« ë²ˆì§¸ ìƒí™©: ì‹ë‹¹ì—ì„œ ìŒì‹ ì£¼ë¬¸í•˜ê¸°\n",
                "situation_1 = \"ì €ëŠ” ì‹ë‹¹ì— ê°€ì„œ ìŒì‹ì„ ì£¼ë¬¸í•˜ê³  ì‹¶ì–´ìš”\"\n",
                "\n",
                "print(\"ğŸ½ï¸ === ì‹ë‹¹ ì£¼ë¬¸ ìƒí™© ===\")\n",
                "print(chain.invoke({\"question\": situation_1}))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë‘ ë²ˆì§¸ ìƒí™©: ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤ì‹œê°„ í•™ìŠµ ê²½í—˜\n",
                "situation_2 = \"ë¯¸êµ­ì—ì„œ í”¼ì ì£¼ë¬¸\"\n",
                "\n",
                "print(\"ğŸ• === ë¯¸êµ­ í”¼ì ì£¼ë¬¸ ìƒí™© (ìŠ¤íŠ¸ë¦¬ë°) ===\")\n",
                "# ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì˜ì–´ íšŒí™”ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ê³¼ì • ê´€ì°°\n",
                "answer = chain.stream({\"question\": situation_2})\n",
                "stream_response(answer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì™„ì„±ëœ Chainì„ ì‹¤í–‰í•˜ì—¬ ë‹µë³€ì„ ì–»ìŠµë‹ˆë‹¤.\n",
                "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­\n",
                "answer = chain.stream({\"question\": \"ì €ëŠ” ì‹ë‹¹ì— ê°€ì„œ ìŒì‹ì„ ì£¼ë¬¸í•˜ê³  ì‹¶ì–´ìš”\"})\n",
                "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
                "stream_response(answer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì´ë²ˆì—ëŠ” question ì„ 'ë¯¸êµ­ì—ì„œ í”¼ì ì£¼ë¬¸'ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
                "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­\n",
                "answer = chain.stream({\"question\": \"ë¯¸êµ­ì—ì„œ í”¼ì ì£¼ë¬¸\"})\n",
                "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
                "stream_response(answer)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
