{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš—ï¸ LCEL í•µì‹¬ ê°œë… ì´í•´í•˜ê¸°\n",
    "\n",
    "### ğŸ”— íŒŒì´í”„ë¼ì¸(Pipeline)ì´ë€?\n",
    "\n",
    "**LCELì˜ í•µì‹¬ì€ íŒŒì´í”„ë¼ì¸ ì—°ì‚°ì `|`** ì…ë‹ˆë‹¤. ì´ëŠ” **Unix íŒŒì´í”„ë¼ì¸**ì—ì„œ ì˜ê°ì„ ë°›ì€ ê°œë…ìœ¼ë¡œ, í•˜ë‚˜ì˜ ì¶œë ¥ì´ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬ë©ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ­ **ê³µì¥ ìƒì‚°ë¼ì¸ìœ¼ë¡œ ì´í•´í•˜ê¸°**\n",
    "\n",
    "```\n",
    "ğŸ“¦ ì›ì¬ë£Œ â†’ ğŸ”¨ ê°€ê³µ1 â†’ âš™ï¸ ê°€ê³µ2 â†’ ğŸ“‹ ê²€ìˆ˜ â†’ âœ… ì™„ì œí’ˆ\n",
    "```\n",
    "\n",
    "LCELë„ ë˜‘ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤:\n",
    "\n",
    "```python\n",
    "# ğŸ”— LCEL ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt_template | model | output_parser\n",
    "#      â†‘              â†‘     â†‘\n",
    "#   1ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ìƒì„± â†’ 2ë‹¨ê³„: AI ì²˜ë¦¬ â†’ 3ë‹¨ê³„: ê²°ê³¼ íŒŒì‹±\n",
    "```\n",
    "\n",
    "### ğŸ¯ ê¸°ë³¸ ì²´ì¸ì˜ 3ë‹¨ê³„ êµ¬ì¡°\n",
    "\n",
    "#### 1ï¸âƒ£ **PromptTemplate** - ğŸ“ ì§€ì‹œì‚¬í•­ ì¤€ë¹„\n",
    "- **ì—­í• **: ì‚¬ìš©ì ì…ë ¥ì„ AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜\n",
    "- **ì…ë ¥**: ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ë³€ìˆ˜ë“¤ (`{\"topic\": \"ì¸ê³µì§€ëŠ¥\"}`)\n",
    "- **ì¶œë ¥**: ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´\n",
    "\n",
    "#### 2ï¸âƒ£ **Model** - ğŸ¤– AI ì²˜ë¦¬ \n",
    "- **ì—­í• **: í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ AIê°€ ë‹µë³€ ìƒì„±\n",
    "- **ì…ë ¥**: í¬ë§·íŒ…ëœ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸\n",
    "- **ì¶œë ¥**: AIMessage ê°ì²´ (ë‚´ìš© + ë©”íƒ€ë°ì´í„°)\n",
    "\n",
    "#### 3ï¸âƒ£ **OutputParser** - ğŸ ê²°ê³¼ ì •ë¦¬\n",
    "- **ì—­í• **: AI ì‘ë‹µì„ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜  \n",
    "- **ì…ë ¥**: AIMessage ê°ì²´\n",
    "- **ì¶œë ¥**: ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë˜ëŠ” êµ¬ì¡°í™”ëœ ë°ì´í„°\n",
    "\n",
    "### ğŸ’¡ íŒŒì´í”„ë¼ì¸ì˜ ê°•ë ¥í•¨\n",
    "\n",
    "```python\n",
    "# ê° ë‹¨ê³„ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ì „í†µì  ë°©ì‹ âŒ\n",
    "formatted_prompt = prompt_template.format(country=\"ëŒ€í•œë¯¼êµ­\")\n",
    "ai_response = model.invoke(formatted_prompt)  \n",
    "final_result = output_parser.parse(ai_response)\n",
    "\n",
    "# LCELë¡œ í•œ ë²ˆì— ì‹¤í–‰í•˜ëŠ” ë°©ì‹ âœ…\n",
    "result = chain.invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\"})\n",
    "```\n",
    "\n",
    "**í•œ ì¤„ë¡œ ì „ì²´ ê³¼ì •ì„ ì™„ë£Œ!** ì´ê²ƒì´ LCELì˜ ë§¤ë ¥ì…ë‹ˆë‹¤. ğŸš€\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ PromptTemplate ì™„ì „ ì •ë³µ\n",
    "\n",
    "**PromptTemplate**ì€ **ë™ì  í”„ë¡¬í”„íŠ¸**ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. ë§ˆì¹˜ **í¸ì§€ ì–‘ì‹**ì— ì´ë¦„ë§Œ ë°”ê¿”ì„œ ì—¬ëŸ¬ ì‚¬ëŒì—ê²Œ ë³´ë‚´ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"LangChain-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”§ PromptTemplateì˜ êµ¬ì„± ìš”ì†Œ\n",
    "\n",
    "**PromptTemplate**ì€ **í…œí”Œë¦¿ ì—”ì§„**ì˜ ì—­í• ì„ í•˜ë©°, ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ **ë™ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±**í•©ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ“‹ **í•µì‹¬ êµ¬ì„± ìš”ì†Œ**\n",
    "\n",
    "1. **ğŸ¯ template**: ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì´ ë‹´ê¸´ ë¬¸ìì—´ í…œí”Œë¦¿\n",
    "   ```python\n",
    "   template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "   ```\n",
    "\n",
    "2. **ğŸ”‘ input_variables**: í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ë“¤ì˜ ì´ë¦„ ëª©ë¡\n",
    "   ```python\n",
    "   # ì¤‘ê´„í˜¸ {} ì•ˆì˜ ë³€ìˆ˜ëª…ë“¤ì´ input_variablesê°€ ë¨\n",
    "   # ìœ„ ì˜ˆì‹œì—ì„œëŠ” [\"country\"]ê°€ ìë™ìœ¼ë¡œ ì¶”ì¶œë¨\n",
    "   ```\n",
    "\n",
    "#### ğŸ’¡ **í…œí”Œë¦¿ ë³€ìˆ˜ ì‚¬ìš©ë²•**\n",
    "\n",
    "- **ì¤‘ê´„í˜¸ `{}`** ì•ˆì— ë³€ìˆ˜ëª… ì‘ì„±\n",
    "- **ì—¬ëŸ¬ ë³€ìˆ˜** ì‚¬ìš© ê°€ëŠ¥: `\"{name}ë‹˜, {city}ì˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?\"`\n",
    "- **ë³€ìˆ˜ëª…ì€ ì˜ë¬¸ìë¡œ ì‹œì‘**, ìˆ«ìì™€ ì–¸ë”ìŠ¤ì½”ì–´ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "#### ğŸš€ **from_template() ë©”ì„œë“œì˜ í¸ë¦¬í•¨**\n",
    "\n",
    "```python\n",
    "# âœ… ê°„ë‹¨í•œ ë°©ë²• - from_template() ì‚¬ìš© (ê¶Œì¥)\n",
    "prompt = PromptTemplate.from_template(\"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\")\n",
    "\n",
    "# âŒ ë³µì¡í•œ ë°©ë²• - ì§ì ‘ ìƒì„± (ë¹„ê¶Œì¥)  \n",
    "prompt = PromptTemplate(\n",
    "    template=\"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "```\n",
    "\n",
    "**from_template()ì˜ ì¥ì :**\n",
    "- **ğŸ” ìë™ ë³€ìˆ˜ ì¶”ì¶œ**: ì¤‘ê´„í˜¸ ì•ˆì˜ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì¸ì‹\n",
    "- **âœ¨ ê°„ê²°í•œ ì½”ë“œ**: í•œ ì¤„ë¡œ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ\n",
    "- **ğŸ›¡ï¸ ì˜¤ë¥˜ ë°©ì§€**: ë³€ìˆ˜ëª… ì˜¤íƒ€ë‚˜ ëˆ„ë½ ìœ„í—˜ ìµœì†Œí™”\n",
    "\n",
    "ì‹¤ì œë¡œ PromptTemplateì„ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤! ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜ì™€ PromptTemplate í´ë˜ìŠ¤ ì„í¬íŠ¸\n",
    "from langchain_teddynote.messages import stream_response\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ—ï¸ PromptTemplate ê°ì²´ ìƒì„±í•˜ê¸°\n",
    "\n",
    "`from_template()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ê°„ë‹¨í•˜ê²Œ PromptTemplate ê°ì²´ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë™ì  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ - {country} ë¶€ë¶„ì´ ë³€ìˆ˜ë¡œ ëŒ€ì²´ë¨\n",
    "template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "\n",
    "# from_template ë©”ì„œë“œë¥¼ ì´ìš©í•˜ì—¬ PromptTemplate ê°ì²´ ìƒì„±\n",
    "# ì¤‘ê´„í˜¸ ì•ˆì˜ ë³€ìˆ˜ë“¤ì´ ìë™ìœ¼ë¡œ input_variablesë¡œ ì¸ì‹ë¨\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# ìƒì„±ëœ PromptTemplate ê°ì²´ í™•ì¸\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…œí”Œë¦¿ì— êµ¬ì²´ì ì¸ ê°’ì„ ëŒ€ì…í•˜ì—¬ ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "prompt = prompt_template.format(country=\"ëŒ€í•œë¯¼êµ­\")\n",
    "print(f\"ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ë¥¸ êµ­ê°€ë¡œ ë³€ê²½í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "prompt = prompt_template.format(country=\"ë¯¸êµ­\")\n",
    "print(f\"ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì„í¬íŠ¸ ë° ì´ˆê¸°í™”\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI GPT ëª¨ë¸ ê°ì²´ ìƒì„±\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1\",  # ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •\n",
    "    temperature=0.1,  # ì°½ì˜ì„± ì¡°ì ˆ (ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ë‹µë³€)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”— LCEL ì²´ì¸ ìƒì„± - íŒŒì´í”„ë¼ì¸ì˜ ë§ˆë²•\n",
    "\n",
    "### ğŸ¯ LCEL(LangChain Expression Language) ì‹¬í™” ì´í•´\n",
    "\n",
    "![LCEL Pipeline](./images/lcel.png)\n",
    "\n",
    "**LCELì˜ í•µì‹¬ì€ `|` (íŒŒì´í”„) ì—°ì‚°ì**ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì—¬ëŸ¬ êµ¬ì„± ìš”ì†Œë¥¼ **ì²´ì¸ì²˜ëŸ¼ ì—°ê²°**í•˜ì—¬ í•˜ë‚˜ì˜ í†µí•©ëœ ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ”„ íŒŒì´í”„ë¼ì¸ ì—°ì‚°ìì˜ ì‘ë™ ì›ë¦¬\n",
    "\n",
    "```python\n",
    "chain = prompt_template | model | output_parser\n",
    "```\n",
    "\n",
    "#### ğŸ“Š ë°ì´í„° íë¦„ ê³¼ì •\n",
    "\n",
    "1. **ğŸ“¥ ì…ë ¥**: `{\"topic\": \"ì¸ê³µì§€ëŠ¥\"}` (ë”•ì…”ë„ˆë¦¬)\n",
    "2. **ğŸ“ 1ë‹¨ê³„**: `prompt_template` â†’ ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸\n",
    "3. **ğŸ¤– 2ë‹¨ê³„**: `model` â†’ AIMessage ê°ì²´ (AI ì‘ë‹µ)  \n",
    "4. **ğŸ 3ë‹¨ê³„**: `output_parser` â†’ ìµœì¢… í…ìŠ¤íŠ¸ ê²°ê³¼\n",
    "\n",
    "### ğŸ› ï¸ Unix íŒŒì´í”„ë¼ì¸ê³¼ì˜ ìœ ì‚¬ì \n",
    "\n",
    "**Unix ëª…ë ¹ì–´**ì™€ ê°œë…ì´ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤:\n",
    "\n",
    "```bash\n",
    "# Unix íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ\n",
    "cat file.txt | grep \"keyword\" | wc -l\n",
    "```\n",
    "\n",
    "```python\n",
    "# LCEL íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ  \n",
    "chain = prompt | model | parser\n",
    "```\n",
    "\n",
    "**ê³µí†µì :**\n",
    "- **â¬…ï¸ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½**ìœ¼ë¡œ ë°ì´í„° íë¦„\n",
    "- **ğŸ”— ê° ë‹¨ê³„ì˜ ì¶œë ¥**ì´ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥ì´ ë¨\n",
    "- **ğŸ§© ëª¨ë“ˆí™”**: ê° êµ¬ì„±ìš”ì†Œë¥¼ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ê³  êµì²´ ê°€ëŠ¥\n",
    "\n",
    "### ğŸ’¡ LCELì´ í˜ì‹ ì ì¸ ì´ìœ \n",
    "\n",
    "#### âœ¨ **ìë™ ìµœì í™”**\n",
    "- **ë³‘ë ¬ ì²˜ë¦¬**: ê°€ëŠ¥í•œ ë¶€ë¶„ì€ ë™ì‹œì— ì‹¤í–‰\n",
    "- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ì¤‘ê°„ ê²°ê³¼ì˜ ìŠ¤ë§ˆíŠ¸í•œ ê´€ë¦¬\n",
    "- **ìŠ¤íŠ¸ë¦¬ë°**: ì‹¤ì‹œê°„ ê²°ê³¼ ì¶œë ¥ ì§€ì›\n",
    "\n",
    "#### ğŸ”§ **ê°œë°œì ì¹œí™”ì **\n",
    "- **ì§ê´€ì  ë¬¸ë²•**: ë°ì´í„° íë¦„ì„ í•œëˆˆì— íŒŒì•…\n",
    "- **ë””ë²„ê¹… ìš©ì´**: ê° ë‹¨ê³„ë³„ ê²°ê³¼ ì¶”ì  ê°€ëŠ¥\n",
    "- **ì¬ì‚¬ìš©ì„±**: êµ¬ì„±ìš”ì†Œë¥¼ ë‹¤ë¥¸ ì²´ì¸ì—ì„œë„ í™œìš©\n",
    "\n",
    "ì´ì œ ì‹¤ì œë¡œ ê°„ë‹¨í•œ ì²´ì¸ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤! ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "prompt = PromptTemplate.from_template(\"{topic}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ê°ì²´ ìƒì„±\n",
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0.1)\n",
    "\n",
    "# ê¸°ë³¸ ì²´ì¸ êµ¬ì„± (ì¶œë ¥ íŒŒì„œ ì—†ì´) - í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ë§Œ ì—°ê²°\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âš¡ invoke() ë©”ì„œë“œ - ì²´ì¸ ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "**invoke()** ëŠ” LCEL ì²´ì¸ì„ ì‹¤í–‰í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ ë©”ì„œë“œì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ“‹ **ì‚¬ìš©ë²•**\n",
    "- **ì…ë ¥ í˜•íƒœ**: Python ë”•ì…”ë„ˆë¦¬ `{\"ë³€ìˆ˜ëª…\": \"ê°’\"}`\n",
    "- **ì‹¤í–‰ ë°©ì‹**: ë™ê¸°ì‹ (ê²°ê³¼ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°)\n",
    "- **ë°˜í™˜ê°’**: ì²´ì¸ì˜ ìµœì¢… ì¶œë ¥ (ì¶œë ¥ íŒŒì„œì— ë”°ë¼ ë‹¬ë¼ì§)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ì‹¤í–‰ì„ ìœ„í•œ ì…ë ¥ ë”•ì…”ë„ˆë¦¬ ì •ì˜\n",
    "# í‚¤ëŠ” í…œí”Œë¦¿ì˜ ë³€ìˆ˜ëª…ê³¼ ì¼ì¹˜í•´ì•¼ í•¨\n",
    "input = {\"topic\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL ì²´ì¸ ì‹¤í–‰: í”„ë¡¬í”„íŠ¸ ìƒì„± â†’ ëª¨ë¸ ì²˜ë¦¬ â†’ AIMessage ë°˜í™˜\n",
    "# invoke() ë©”ì„œë“œë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í•œ ë²ˆì— ì‹¤í–‰\n",
    "result = chain.invoke(input)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (AIMessage ê°ì²´ í˜•íƒœë¡œ ë°˜í™˜ë¨)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒŠ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì˜ ê°•ë ¥í•¨\n",
    "\n",
    "**ìŠ¤íŠ¸ë¦¬ë°**ì€ AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” **ì‹¤ì‹œê°„ ê³¼ì •ì„ ê´€ì°°**í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. ë§ˆì¹˜ ì‚¬ëŒì´ ë§í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë‹¨ì–´ í•˜ë‚˜ì”© ë‚˜íƒ€ë‚©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì²´ì¸ ì‹¤í–‰ - ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µ ìƒì„± ê³¼ì • í™•ì¸\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# langchain_teddynoteì˜ í—¬í¼ í•¨ìˆ˜ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ê¹”ë”í•˜ê²Œ í‘œì‹œ\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ OutputParser - ê²°ê³¼ë¥¼ ì›í•˜ëŠ” í˜•íƒœë¡œ\n",
    "\n",
    "**OutputParser**ëŠ” AIì˜ ë³µì¡í•œ ì‘ë‹µì„ **ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜**í•´ì£¼ëŠ” ë§ˆì§€ë§‰ ë‹¨ê³„ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ ì„í¬íŠ¸\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# StrOutputParser ê°ì²´ ìƒì„± - AIMessageì—ì„œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”— ì™„ì „í•œ ì²´ì¸ êµ¬ì„±í•˜ê¸°\n",
    "\n",
    "ì´ì œ **3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸**ì„ ì™„ì„±í•´ë´…ì‹œë‹¤: **PromptTemplate â†’ Model â†’ OutputParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì™„ì „í•œ LCEL ì²´ì¸ êµ¬ì„±: í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ ì¶œë ¥ íŒŒì„œ\n",
    "# ì´ì œ ê²°ê³¼ê°€ AIMessageê°€ ì•„ë‹Œ ìˆœìˆ˜ ë¬¸ìì—´ë¡œ ë°˜í™˜ë¨\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì™„ì„±ëœ ì²´ì¸ìœ¼ë¡œ invoke ì‹¤í–‰ - ì´ì œ ìˆœìˆ˜ ë¬¸ìì—´ì´ ë°˜í™˜ë¨\n",
    "input = {\"topic\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"}\n",
    "result = chain.invoke(input)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (ì´ì œ ë¬¸ìì—´ í˜•íƒœë¡œ ê¹”ë”í•˜ê²Œ ì¶œë ¥ë¨)\n",
    "print(\"=== ì™„ì„±ëœ ì²´ì¸ ê²°ê³¼ ===\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì™„ì„±ëœ ì²´ì¸ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰\n",
    "answer = chain.stream(input)\n",
    "\n",
    "print(\"=== ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ===\")\n",
    "# ì‹¤ì‹œê°„ìœ¼ë¡œ ë¬¸ìì—´ì´ ìƒì„±ë˜ëŠ” ê³¼ì •ì„ ê´€ì°°\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ì‹¤ì „ í”„ë¡œì íŠ¸: ì˜ì–´ íšŒí™” íŠœí„° AI ë§Œë“¤ê¸°\n",
    "\n",
    "ì´ì œ ë°°ìš´ ë‚´ìš©ì„ í™œìš©í•´ì„œ **ì‹¤ìš©ì ì¸ ì˜ì–´ í•™ìŠµ ë„ìš°ë¯¸**ë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤! \n",
    "\n",
    "### ğŸ’¡ í”„ë¡œì íŠ¸ ê°œìš”\n",
    "\n",
    "- **ëª©í‘œ**: ìƒí™©ë³„ ì˜ì–´ íšŒí™” ìƒì„± + í•œê¸€ ë²ˆì—­ ì œê³µ\n",
    "- **íŠ¹ì§•**: ì²´ê³„ì ì¸ í¬ë§·ìœ¼ë¡œ í•™ìŠµ íš¨ê³¼ ê·¹ëŒ€í™”\n",
    "- **í™œìš©**: ë‹¤ì–‘í•œ ìƒí™©ì— ë§ëŠ” ì˜ì–´ í‘œí˜„ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ë¬¸ì ì¸ ì˜ì–´ íšŒí™” íŠœí„° í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ê³„\n",
    "template = \"\"\"You are an experienced English conversation teacher with 10 years of expertise.\n",
    "Create practical English conversations for the given situation with Korean translations.\n",
    "Please follow the FORMAT exactly as shown below.\n",
    "\n",
    "#SITUATION:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- English Conversation:\n",
    "- Korean Translation:\n",
    "- Useful Expressions:\n",
    "- Cultural Notes (if applicable):\n",
    "\"\"\"\n",
    "\n",
    "# ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ê°ì²´ ìƒì„± (ìµœì‹  ëª¨ë¸ ì‚¬ìš©)\n",
    "model = ChatOpenAI(model_name=\"gpt-4.1\")\n",
    "\n",
    "# ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ ìƒì„±\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ì–´ íšŒí™” íŠœí„° ì²´ì¸ êµ¬ì„±\n",
    "# í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ ì¶œë ¥ íŒŒì„œì˜ ì™„ì „í•œ íŒŒì´í”„ë¼ì¸\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ ìƒí™©: ì‹ë‹¹ì—ì„œ ìŒì‹ ì£¼ë¬¸í•˜ê¸°\n",
    "situation_1 = \"ì €ëŠ” ì‹ë‹¹ì— ê°€ì„œ ìŒì‹ì„ ì£¼ë¬¸í•˜ê³  ì‹¶ì–´ìš”\"\n",
    "\n",
    "print(\"ğŸ½ï¸ === ì‹ë‹¹ ì£¼ë¬¸ ìƒí™© ===\")\n",
    "print(chain.invoke({\"question\": situation_1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‘ ë²ˆì§¸ ìƒí™©: ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤ì‹œê°„ í•™ìŠµ ê²½í—˜\n",
    "situation_2 = \"ë¯¸êµ­ì—ì„œ í”¼ì ì£¼ë¬¸\"\n",
    "\n",
    "print(\"ğŸ• === ë¯¸êµ­ í”¼ì ì£¼ë¬¸ ìƒí™© (ìŠ¤íŠ¸ë¦¬ë°) ===\")\n",
    "# ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì˜ì–´ íšŒí™”ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ê³¼ì • ê´€ì°°\n",
    "answer = chain.stream({\"question\": situation_2})\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì™„ì„±ëœ Chainì„ ì‹¤í–‰í•˜ì—¬ ë‹µë³€ì„ ì–»ìŠµë‹ˆë‹¤.\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­\n",
    "answer = chain.stream({\"question\": \"ì €ëŠ” ì‹ë‹¹ì— ê°€ì„œ ìŒì‹ì„ ì£¼ë¬¸í•˜ê³  ì‹¶ì–´ìš”\"})\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë²ˆì—ëŠ” question ì„ 'ë¯¸êµ­ì—ì„œ í”¼ì ì£¼ë¬¸'ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­\n",
    "answer = chain.stream({\"question\": \"ë¯¸êµ­ì—ì„œ í”¼ì ì£¼ë¬¸\"})\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
